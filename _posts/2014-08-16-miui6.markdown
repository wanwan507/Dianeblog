---
layout:     post
title:      "深度学习巨头Yann Lecun 中科院自动化所座谈及清华大学讲座"
date:       2017-07-14 12:00:00
author:     "Diane"
header-img: "img/post-alpha-zero.jpg"
tags:
    - 知乎
    - 深度学习
---


<div>
    2017年3月22日星期三，空气重度污染的北京迎来了人工智能领域一位重量级的嘉宾——Facebook人工智能实验室主任，卷积神经网络的发明人Yann Lecun教授。Yann Lecun一行上午在中国科学院自动化研究所举行了40分钟的小型座谈会，下午在清华大学举办了“深度学习与人工智能的未来”主题演讲。笔者有幸全程参与了上述两项活动，现将活动的主要内容及个人感悟与大家分享，欢迎各位分享、转发。未经本人授权，任何组织、个人不得擅自使用本文的文字及图片资料。

    上午 中国科学院自动化研究所智能化大厦17层紫东咖啡厅 主场

    Lecun的到来所里之前也没有做过多的宣传，可能是由于上一次Andrew NG来做报告，整个学术报告厅被挤爆，这一次所里只举行了一个40人左右小而精的座谈会。主要形式以嘉宾和听众互动为主。座谈会的主持人是我们的副所长刘成林研究员，主要嘉宾包括Yann Lecun教授，Facebook 副总裁企业发展副总裁Vaughan Smith博士和田渊栋博士。

    座谈会的开始，刘所长进行了热情而简短的欢迎致辞，接下来就以问答互动的形式开始了座谈。每一个问题我可能无法全部记清楚，现把我自己印象比较深刻的问题简要总结，部分问题在下午清华的讲座中也谈到了。其中一位同学谈到了了深度学习目前还没有相关理论解释的问题。Lecun的观点是，并非所有的研究都是现有理论后有实践，很多问题都是人们先发现了某种现象，后来才找到了合理的理论解释。在下午清华的讲座的QA环节，Lecun又举了几个具体例子，瓦特发明蒸汽机是在动力学理论之前，人们最早发明飞机的时候，也没有完善的空气动力学理论。深度学习就是理论在实践之后。刘所长问了一个关于GAN的问题，Lecun对GAN赞不绝口，并补充说明了GAN不是他自己的idea，是Ian Goodfellow在读博士期间提出来的，下午清华讲座中有关于GAN的详细介绍，这里暂不展开。还有同学问到了哪些领域深度学习并不work，Lecun回答是也谈到了Logistic Regression这些较为经典的模型可以发挥威力的场景。（笔者补充：其实当我们的数据量较小的时候，深度学习的效果可能没有传统的经典模型那么好）。很幸运自己获得了座谈会最后的一个提问机会，我的问题是关于深度学习对抗样本的，深度学习在计算机视觉、语音识别、自然语言处理都取得了突破性的进展，但是研究者也发现深度神经网络也是很容易被愚弄的，当对一张图片加上人为的噪声之后，系统会将其错误分类，类似的现象在强化学习领域里也被观察到，智能体可能会被攻击者误导执行错误的动作，对抗样本和AI的安全密切相关，对此，您有何评论？Lecun说到这是一个很好的问题，他在做手写字符识别的时候也注意到了这种现象，当时为了探索什么图像会让卷积网络完美的预测一个数字4，然后将梯度反向传播的输入图像，所得到的结果和预想的是不一样的。他认为非监督学习是解决对抗样本问题的一个比较有效的思路。在座谈会的最后，刘所长请Yann Lecun教授给在座的同学一句寄语，Lecen教授说我们现在正处于一个AI发展很好的时代，未来AI取得的重要突破，在座的同学就可能扮演重要的角色。教授的谆谆教诲真是给我我等莫大的学习动力。

</div>
