<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bingjie Blog</title>
    <description>关于深度学习与量化交易、黑客与画家 | 高冰洁，Deep Learning &amp; Quantitive Analysis，Nature Language Processing，Machine Learning | 这里是 @Diane冰洁 的个人博客，与你一起发现更大的世界。</description>
    <link>http://0.0.0.0:80/</link>
    <atom:link href="http://0.0.0.0:80/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Mon, 30 Oct 2017 21:26:00 +0800</pubDate>
    <lastBuildDate>Mon, 30 Oct 2017 21:26:00 +0800</lastBuildDate>
    <generator>Jekyll v3.5.0</generator>
    
      <item>
        <title>阅读alpha zero笔记</title>
        <description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;#build&quot;&gt;很久没有更新了…&lt;/a&gt;&lt;/p&gt;

&lt;p id=&quot;build&quot;&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;##阅读alpha zero笔记&lt;/p&gt;

&lt;p&gt;####什么是alpha zero&lt;/p&gt;

&lt;p&gt;最近，AlphaGo成为围棋中的击败世界冠军的第一个程序。在评价与选择alphago位置移动使用深度神经网络树搜索。这些神经网络是通过专家学习的有监督学习和自我学习强化学习训练而成的。在这里，我们介绍了一个完全基于强化学习的算法，没有人类数据，指导，或超越游戏规则的领域知识。alphago成为自己的老师：训练一个神经网络来预测AlphaGo的行动选择和AlphaGo比赛的胜者。该神经网络提高了树搜索的力量，重新形成更高质量的移动选择，在下一次迭代中更强的自我发挥。我们的新项目alphago零取得了超人的业绩，赢得对先前公布的100-0，将alphago冠军击败。&lt;/p&gt;

&lt;p&gt;####序&lt;/p&gt;

&lt;p&gt;人工智能已取得很大进展，使用受过训练的专家系统来复制人类专家的决策。然而，专家数据通常是昂贵的、不可靠的，或者根本不可用。即使有可靠的数据，它也可能对以这种方式培训的系统的性能造成限制。相反，强化学习系统是从他们自己的经验中训练出来的，原则上允许他们超越人的能力，并在缺乏专业知识的领域运作。&lt;/p&gt;

&lt;p&gt;发布的版本，我们称之为AlphaGo Fan，2015年10月击败欧洲冠军范辉。alphago利用两深层神经网络：策略网络的输出转移概率，和价值网络的输出位置的评价。策略网络最初是通过有监督的学习来精确预测人类专家的移动，随后通过政策梯度强化学习加以改进。价值网被训练以预测政策网络对自身的博弈赢家。一旦经过训练，这些网络结合蒙特卡洛树搜索（MCTS）提供前向搜索，运用政策网络来缩小搜索的高概率的动作，并利用价值网的工作（在蒙特卡洛推广使用快速推出政策一起）评价树中的位置。&lt;/p&gt;

&lt;p&gt;它只由自我播放强化学习训练，从随机播放开始，没有任何监督或使用人的数据。其次，它只使用棋盘上的黑白石头作为输入特征。第三，它使用单一的神经网络，而不是单独的政策和价值网络。最后，它使用了一个简单的搜索树，依靠这种单一的神经网络进行位置和样品时，不执行任何Monte-Carlo展示。为了实现这些结果，我们引入一个新的增强算法，采用前向搜索里面的训练循环学习，从而迅速提高、精确和稳定的学习。&lt;/p&gt;

&lt;p&gt;####alpha zero中的强化学习&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;新方法使用深度神经网络参数Fθ（θ）。该神经网络作为输入，其历史地位的原始表示，移动和输出概率，和一个值（p，v）= Fθ（S）。转移概率向量代表选择每一步的概率（包括通过），PA = PR(a&lt;/td&gt;
      &lt;td&gt;S）。v值是一个标量估计，估计当前玩家从位置S中获胜的概率。这个神经网络将策略网络和价值网络的角色结合成一个单一的体系结构。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;在alphago zero 的神经网络是由一种新型的强化学习算法训练自我发挥的游戏。在每一个位置，一个能执行搜索，通过神经网络θ引导F。MCTS搜索输出概率π玩的每一个动作。这些搜索概率通常选择更强的动作比原移动概率神经网络的Fθ（S）；MCTS可能因此被看作是一个强大的政策改进算子。采用改进的基于策略的选择MCTS每个移动搜索，然后用游戏的赢家Z为价值–样品可以被看作是一个强有力的策略评价算子。强化学习算法的主要思想是在策略迭代程序重复使用搜索操作符：神经网络的参数进行更新，使转移概率值（p，v）= Fθ（S）更密切地配合改进的搜索概率和自我发挥的赢家（π，Z）；这些使用新的参数在自我的下一次迭代的发挥使搜索更强大。图1展示了自播放训练流水线。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/alphazero1.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;蒙特卡洛树搜索使用神经网络Fθ指导其模拟（见图2）。搜索树中的每个边（s，a）存储一个先验概率p（s，a），访问计数n（s，a），和一个动作值q（s，a）。每个模拟从根的状态和反复选择的动作，最大限度的置信上界Q（s，a）+ U（S，A），其中U（S，A）∝P（S，A）/（1 + N（S，A）），直到一个叶节点 s’ 是遇到。这叶位扩展和评估只是一次由网络产生的先验概率和评估，（P（S’，·）、V（S’））= Fθ（S’）。
每个边缘（S，A）经过模拟更新来增加它的访问数N（S，A），并更新它的平均评价在这些模拟交易价值，Q（s，a）= 1 / N（S，A）s’| S，a→s’V（S’），其中S，a→s’表明模拟最终达成s’服用后移动一个位置S.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/alphazero2.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;MCTS可以被看作是一个自我发挥的算法，给出了神经网络参数θ和根的位置，计算搜索概率，π=αθ（S），与访问动作个数的幂成正比，π一∝N（S，A）1 /τ，其中τ是温度参数。&lt;/p&gt;

&lt;p&gt;神经网络是由一个自我发挥的强化学习算法，采用能发挥每个移动训练。首先，神经网络权值初始化随机θ0。在每次重复i≥1，自玩游戏产生了（图1A）。在每一个时间步t，一个MCTS搜索πT =αθi−1（ST）是利用神经网络的Fθi−1以前的迭代执行，和移动是通过采样的搜索概率πT.游戏终止于步当双方都被pass，当搜索值低于辞职的门槛，或当游戏超过最大长度；游戏则拿给最终的奖赏rt∈{-1，1 } 。每个时间步t的数据存储为（ST，πT，ZT），ZT =±RT是游戏赢家从当前玩家的视角在步骤T.于此平行的参见（图1b），新的网络参数θi训练数据（S，π，Z）均匀采样的最后一次迭代步骤中的所有时间（S）自我发挥。神经网络（p，v）= Fθi（s）是调整为最小预测值V和自我发挥的赢家Z之间的误差，并最大限度地提高神经网络的转移概率的相似性搜索的概率π。具体来说，参数的调整θ梯度下降的损失函数L分别是均方误差和交叉熵的损失，其中C是L2正则化参数控制体重水平（防止过拟合）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/alphazero3.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;####alpha zero的经验训练&lt;/p&gt;

&lt;p&gt;我们应用我们的强化学习管道来训练我们的程序alphago零。训练从完全随机的行为开始，持续3天没有人工干预。&lt;/p&gt;

&lt;p&gt;在训练过程中，自490万场比赛共产生1600，使用模拟每个MCTS，相当于约每移动0.4s思考时间。参数从700000个小批量2048个位置更新。神经网络包含20个剩余块（见进一步细节的方法）。&lt;/p&gt;

&lt;p&gt;alphago零自我发挥强化学习期间的表现，作为培训时间的函数，在ELO评分25。在整个训练过程中，学习进展顺利，并没有受到先前文献中所提出的振荡或灾难性遗忘的影响。令人惊讶的是，alphago零比AlphaGo Lee后仅36小时；相比之下，AlphaGo Lee被训练好几个月了。72个小时后，我们评估alphago零对AlphaGo Lee打败了Lee Sedol的版本，2小时的时间控制和匹配的条件下在汉城的人机匹配使用。alphago零使用单机4张量处理单元（TPU）而AlphaGo Lee分布在许多机器和使用48个。alphago零击败AlphaGo Lee以100比0（参见扩展数据图5和补充资料）。&lt;/p&gt;

&lt;p&gt;评估自我发挥强化学习的优点，相对于从人体数据的学习，我们训练的第二神经网络（使用相同的架构）预测的数据集；取得了国家的最先进的预测精度比以前的工作。监督学习取得了更好的初始性能，并且更好地预测了人类职业游戏的结果。值得注意的是，虽然有监督的学习取得了较高的移动预测精度，自学的玩家表现得更好，总体而言，击败了受过训练的玩家在头24小时的培训。这表明，alphago零可以学习的策略，是对人类起到质的不同。&lt;/p&gt;

&lt;p&gt;为了分离的结构和算法的贡献，我们用alphago零的神经网络体系结构的性能与以前的神经网络结构与AlphaGo Lee相比（见图4）。四个神经网络创建了，可以使用独立的政策和价值网络；用AlphaGo Lee或alphago零剩余网络架构的卷积网络架构。每个网络进行训练，最大限度地减少相同的损失函数（公式1）使用一个固定的数据集生成的alphago零自玩游戏72小时后自游戏训练。利用剩余网络更准确，达到较低的错误，和改进的性能在alphago超过600的Elo。结合政策和价值结合成一个单一的网络，降低移动的预测精度，但降低值误差和性能的提高起alphago大约600的Elo。这部分是由于提高了计算效率，但更重要的是双重目的规范网络共同表示支持多个用例。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/alphazero4.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;####alpha zero学到的知识&lt;/p&gt;

&lt;p&gt;随后我们将我们的强化学习的管道，使用一个更大的神经网络的alphago零的第二个实例，在一个较长的时间。训练又从完全随机的行为开始，持续了大约40天。
在训练过程中，产生了2900万个自我游戏。参数从310万个小批次中更新，每个2048个位置。神经网络包含40个残差块。在整个训练过程中定期播放的游戏在扩展数据图4和补充信息中显示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/alphazero5.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;图5：去alphago零知识。一个五人的定式（普通角序列）在alphago零发现训练。相关的时间戳显示第一次每个序列发生（以旋转和反射的帐户）自我发挥训练中。扩展数据图1为每个序列提供了超过训练的频率。B五定式的青睐在自我发挥不同训练阶段。每一个显示的角落序列在所有的角落序列中发挥最大的频率，在自我游戏训练的迭代中。该迭代的时间戳在时间轴上表示。在10小时内，弱角移动是首选。在47小时的3-3的入侵是最常播放的。这个定式人专业玩也很常见；然而alphago零后来发现和优选的新变化。扩展数据图2为所有五个序列和新的变化提供了随时间变化的频率。C三自玩游戏，在训练的不同阶段起着第一80个动作，使用1600个模拟（约0.4s）每搜索。在3小时内，游戏专注于捕捉石头，就像人类的初学者一样。在19小时内，游戏展现了生死、影响力和领土的基本面。在70小时内，这场比赛是完美的平衡，涉及多个战斗和复杂的KO战斗，最终解决了半分的胜利为白色。有关完整游戏的补充信息。&lt;/p&gt;

&lt;p&gt;####结论
我们的研究结果全面证明，纯强化学习方法是完全可行的，即使是在最具挑战性的领域中：如果没有基本规则之外的领域知识，就有可能训练到超人级，没有人类实例或指导。此外，纯强化学习方法只需要训练几个小时，与人类专家数据训练相比，它取得了更好的渐近性能。使用这种方法，alphago零打败alphago最强的以前的版本，这是使用手工制作的特征的人体数据进行训练，大幅度。
人类从几千年来玩过的游戏中积累了大量的知识，并融为模式、谚语和书籍。在短短几天内，启动白板，alphago零能够重新发现许多这样的围棋知识，以及新的策略。&lt;/p&gt;

</description>
        <pubDate>Mon, 30 Oct 2017 20:00:00 +0800</pubDate>
        <link>http://0.0.0.0:80/2017/10/30/alphazero/</link>
        <guid isPermaLink="true">http://0.0.0.0:80/2017/10/30/alphazero/</guid>
        
        
      </item>
    
      <item>
        <title>东方证券金工研报阅读</title>
        <description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;#build&quot;&gt;感冒依旧没有好…&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;总结一下昨天晚上看的8篇研报&lt;/p&gt;

&lt;p id=&quot;build&quot;&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;h2 id=&quot;正文&quot;&gt;正文&lt;/h2&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;p&gt;
多因子选股模型的整个投资流程包括 alpha 模型的构建，风险模型的构建， 交易成本模型的构建，投资组合优化过程以及组合业绩的归因分析。从国内 市场上已公开的量化模型看，采取的大多是打分法选股或者行业、市值分层 构建组合，这种组合构建方式缺乏对风险和 alpha 的精确控制，最终组合可 能偏离预定的投资目标。&lt;/p&gt;

&lt;p&gt;多因子结构化风险模型(如 Barra, Axioma)目前仍然是市场上的主流风险模型。&lt;/p&gt;

&lt;p&gt;构建了alpha模型和交易成本模型，并且在不同的样本空间内进行 投资组合优化回溯测试，实证检验表明基于压缩估计量风险模型构建的组合 能够获得比采用简单分层方法构建的组合更高的风险调整后收益和更低的 换手率，同时，投资组合的优化过程也提供了对组合的权重分配、换手率进 行动态微调的机会。&lt;/p&gt;

&lt;p&gt;对于指数增强基金，我们检验得出传统上的行业中性处理已经能够把组合的 跟踪误差控制在一个相对较小的范围内，而基于压缩估计量构建的风险模型 能够更加精确地控制组合事后跟踪误差，这可以满足指数增强基金经理对组 合主动风险进行精确控制的要求。&lt;/p&gt;

&lt;blockquote&gt;1.多因子模型投资流程&lt;/blockquote&gt;
&lt;p&gt;近年来, 多因子选股策略在国内市场上已经得到了较为广泛的应用，国内各机构也对阿尔法因子的 挖掘和多因子阿尔法模型的构建有了较为充分的研究。但是类似研究在构建组合时大多采取的都是 相对固定的模式，例如通过分层来构造行业中性和市值中性的组合。这类相对主观的调整难以顾及 个股之间和行业之间的关联性，缺乏对组合风险的精确控制，导致最终构建的组合可能并没有充分 暴露在预设的阿尔法因子上。&lt;/p&gt;

&lt;p&gt;风险模型是投资组合优化过程中非常重要的一个组成环节，风险模型旨在捕捉不同股票个体波动性 差异大小和股票之间波动相关性的大小，对股票未来价格的波动进行预测。目前风险模型有如下几种:&lt;/p&gt;
&lt;p&gt;1. 样本协方差矩阵:在资产收益率多元正态分布的假定下，样本协方差矩阵是总体协方差矩阵的 无偏估计量。当投资组合中有 N 个资产时，需要估计的波动率个数为 N，需要估计的协方差 个数为 N(N-1)/2。&lt;/p&gt;

&lt;p&gt;2. 基本面因子模型:目前较为主流的风险模型当属这一类，而且市场上有非常成熟的商业化解决 方案(MSCI Barra, Axioma, Northfield)。在基本面因子模型中，股票收益的系统性风险部分 能够被一组公共的因子所解释。&lt;/p&gt;

&lt;p&gt;3. 宏观因子模型:宏观因子模型与基本面因子模型类似，也是通过一组公共因子来解释股票收益 的系统性风险，比如通货膨胀率，GDP 增长率，利率等。区别主要在于在宏观因子模型中， 我们已知的是每个因子在每一期的因子收益率，而每个股票在这些公共因子上的暴露需要通过 较长历史区间的时间序列回归进行估计。&lt;/p&gt;

&lt;p&gt;4. 统计因子模型: 统计因子模型主要是利用主成分分析从股票收益率样本协方差矩阵提取出一定数量的主成分，主成分的数量由对总方差的解释阈值所确定。类似于基本面因子模型，我们可以通过K个主成分来捕捉N个股票之间的波动情况，降低了需要估计参数的个数。&lt;/p&gt;

&lt;p&gt;
在多因子选股量化投资流程中，阿尔法模型的优劣直接决定了投资组合是否能够获得稳健的超额收 益。 我们将在接下来的研究中深入探讨如何有效地构建多因子模型，本文只做初步介绍。我们对 东方金工因子库中的 7 大类 40 多个因子在中证全指样本空间内进行了因子显著性检验，为了避免 前视偏误(look ahead bias)，因子有效性检验的时间区间为 2006 年 1 月 1 日到 2010 年 12 月 31 日，通过综合考察因子 Rank IC、Rank IC 的 t 统计量、IR、IC 正显著比例、IC 负显著比例、 多空组合收益率、多空组合夏普比以及多空组合最大回撤等绩效指标，筛选出了如下因子作为阿尔 法模型的组成部分:&lt;/p&gt;

&lt;p&gt;我们在每个月末首先计算因子的原始值，然后对原始值做中位数去极值和标准化处理，再针对不同类型的因子做进一步的中性化处理:&lt;/p&gt;
&lt;p&gt;1. 财务类因子(价值、成长)做行业中性处理和风格中性处理，剔除行业和 Beta, 规模的影响。&lt;/p&gt;
&lt;p&gt;2. 对风险类因子中的换手率因子和技术因子做风格中性处理。剔除 Beta, 规模的影响。&lt;/p&gt;
&lt;p&gt;我们的目标是结合公司的基本面指标，风险指标和技术指标。投资逻辑是:购买具有相对低估值的 高成长公司，同时这些公司前期没有被市场过度炒作而高估，并且技术面上反映出这些公司的股价 已经出现超跌的现象。由于中国市场上小盘股效应较为明显，但波动较大，在alpha模型中应当适量控制对小盘股的暴露。&lt;/p&gt;
&lt;p&gt;接下来，可以采用不同的方法把多个因子的信息结合起来，构成合成因子。对于合成因子的构成，可以采用如下几种方式:&lt;/p&gt;
&lt;p&gt;1. 在同类因子内部采取等权重加权，构成每类的合成因子。然后对每类的合成因子采取等权重加权，组成综合的合成因子。最后再对合成因子做标准化处理。&lt;/p&gt;
&lt;p&gt;2. 在各个因子之间相关性较低的情况下可以利用单个因子的历史滚动IR进行加权，每个月动态 调整因子配比。&lt;/p&gt;
&lt;p&gt;3. 利用历史面板数据进行回归，因变量是股票的月度收益，自变量是经过处理后的因子值。利用最新一期的因子值和估计出的参数得到单个股票预期收益的预测值。&lt;/p&gt;

&lt;p&gt;交易成本也是多因子选股模型构建不可缺少的一环。交易成本与组合的权重变化和交易执行策略直接相关。交易成本通常可以分为固定成本和可变成本。固定成本包括交易佣金，印花税和买卖价差(bid-ask spread)。可变成本则包括冲击成本和机会成本。&lt;/p&gt;

&lt;p&gt;在估计出参数以后，我们就可以把交易成本嵌入到优化的目标函数中。由于参数的估计需要涉及到高频的数据，在本文的实证分析中只采用如下固定交易成本的简化假定:&lt;/p&gt;
&lt;p&gt;1. 买入交易成本 1.8‰(佣金 0.8‰ + 冲击成本 1.0‰)，卖出交易成本 2.8‰(佣金 0.8‰ + 印 花税 1.0‰ + 冲击成本 1.0‰)&lt;/p&gt;
&lt;p&gt;2. 假定每次买入金额等于卖出金额，参数  0.5*(2.8‰ + 1.8‰)= 2.4‰&lt;/p&gt;

&lt;p&gt;至此，我们已经完成了投资组合优化三大基石的构建:风险模型，alpha模型和交易成本模型。投资组合优化可以在精确控制组合风险的基础上，最大化组合对预定 alpha 因子的暴露，同时满足其他约束条件。&lt;/p&gt;

&lt;blockquote&gt;Alpha 模型之再认识&lt;/blockquote&gt;
&lt;p&gt;在之前的因子选股系系列报告中，我们系统地讨论了因子的检验、挑选和投资组合的构建问题。本 文将着重讨论如何有效的构建 Alpha 模型。首先需要明确的是，Alpha 模型的最终目标是在给定的 样本空间范围内稳定地预测股票未来收益率的排序，即把”好股票”和”坏股票”区分开来。构建 Alpha 模型最为核心的两个步骤是因子的挑选和不同因子之间权重的分配方式。&lt;/p&gt;
&lt;p&gt;然而，大多数传统 Alpha 模型的一个前提就是对全市场的股票进行一视同仁的打分，然后在全市 场进行排序。我们知道，不同个股的基本面属性可能存在非常大的区别。比如，对于一个低估值、 高ROE和大市值的蓝筹股，它在模型中与一个高估值、低 ROE 和小市值的成长股的可比性会大大降低，这也是传统上的基本面研究以行业或者市值作为划分标准的依据。&lt;/p&gt;
&lt;p&gt;为了解决这个问题，人们开始尝试对每个行业进行单独建模，比如利用各种统计方法检验在每个行业内区分能力最强的因子，利用对该行业有显著效果的因子给行业内的股票进行独立打分，然后再 汇总个股的得分或者排序，从而得到全市场的排序。&lt;/p&gt;
&lt;p&gt;这种方法在一定程度上弥补了全市场统一打分模型的缺陷，承认了个股之间的差异性和不可比性，增加了Alpha模型的广度(Breadth)。但它也存在几个重要的问题:&lt;/p&gt;
&lt;p&gt;1. 传统上的行业分类主要依据是公司收入的来源，而公司收入来源相似不代表公司的基本面完全一致。换句话说，公司收入来源不同(属于在不同的行业)也不代表公司的基本面不同，比如同一个成熟的技术类公司相比，一个高速成长的技术类公司可能和一个高速成长的生物医药公司基本面更为相似。&lt;/p&gt;
&lt;p&gt;2. 公司的行业属性相对稳定，但是公司的基本面并非是一成不变的。一个公司刚上市时，可能是属于小市值，高成长和高估值的成长股，但八到十年后，公司可能具有完全不同的基本面属性，比如已经成为一个大市值，高盈利和低估值的蓝筹股。单纯以行业作为划分依 据难以捕捉公司基本面随时间发生的变化。&lt;/p&gt;
&lt;p&gt;3. 同一个行业内的股票数量相对有限，统计检验出来的有效因子可能是对历史数据噪音的过度拟合，样本外的效果值得怀疑。&lt;/p&gt;
&lt;p&gt;为了解决上述两个问题，Sorenson, Hua and Qian (2005) 首先提出 Dynamic Contextual Alpha 的概念，中文叫做动态情景 Alpha 模型。这个模型摈弃了行业内打分的做法，转而根据股票基本面的属性，比如估值、成长和盈利能力等，把股票分成不同的层面，对每个层面内的股票采用单独 的评价体系进行打分或者排序，最后得到每个股票的综合得分。这个模型已经成功地被运用在波士 顿一家知名的量化资产管理公司-PanAgora Asset Management 的 Dynamic Equity Strategies 策略上，并且取得了优异的业绩。&lt;/p&gt;

&lt;p&gt;在DCA模型的构建中，首先需要考虑的是采用什么因子对股票进行分层。分层的目标是把具有相 似的基本面的股票聚集在一起，同时不同的分层应该能够刻画股票基本面上不同的属性，如规模、价值和成长性等。分层的理想结果是不同的 Alpha 因子在不同的分层(如大市值和小市值，高估值 和低估值)有着显著的绩效区别。最为简单粗暴的方法则是把每个因子都作为分层因子测试一遍， 统计其他因子的预测能力强度，选出综合区分能力最强的因子。但是这种方法缺乏事前逻辑的支撑， 容易掉入数据窥视偏差(Data-Snooping Bias)的陷阱.对历史数据过度拟合(overfitting).&lt;/p&gt;
&lt;p&gt;我们认为分层因子应当具有风险因子的特征，挑选的具体标准如下:&lt;/p&gt;
&lt;p&gt;1. 因子对市场风格的切换具有较强的捕捉能力，具体表现为Rank IC正负显著比例之和在 70% 以上。&lt;/p&gt;
&lt;p&gt;2. 因子本身应当相对稳定，具体表现为较高的线性自相关系数(85%以上)。不同分层因子之间的 因子值的横截面秩相关系数应当较低，能够在不同维度刻画股票的特征。&lt;/p&gt;
&lt;p&gt;3. 因子定义简单，逻辑明确，因子在样本空间的覆盖率高(95%以上)，同时应当覆盖所有行业。&lt;/p&gt;

&lt;p&gt;值得指出的是，由于沪深 300 指数的特殊性，情景 alpha 模型也并非一劳永逸的处理方式，对于 某些特殊的行业，如银行和非银行金融业，仍然需要开发专门的行业选股模型(Industry Model)。&lt;/p&gt;

&lt;p&gt;Alpha 是量化投资的基础概念，但实际使用时存在模糊的地方。通常在大众媒体和私人聊天中 用到的alpha，例如:“XX 基金的 alpha 很高”，实际上指的是相对基准超额收益的意思。而在组合 绩效分析中，股票组合收益可以分解为风险因子(市场因子、市值因子、估值因子等)带来的 beta 收益和不能被这些风险解释的 alpha 收益，随着风险因子的选择不同，计算得到的 alpha 也会不同; 如果任何风险都不控制，那么 alpha 就等于组合收益率。因此严格的来讲，对于不同的投资者，由 于风险控制的要求不一样，追求的 alpha 会有差别，只有在同一个风险控制要求下，比较不同策 略间的 alpha 才有意义。&lt;/p&gt;

&lt;p&gt;机器学习容易给人“黑箱模型”和“过拟合”的印象，但事实上一些机器学 习算法的逻辑和结果都非常直白，而且算法自身带有一套避免过拟合的参数 估计机制。众多的实践研究说明，机器学习方法的预测能力大部分情况下都 强于线性模型，很值得在量化投资中测试使用。本报告主要讲述机器学习的 基本原理和用其来做量化选股的实证结果。&lt;/p&gt;
&lt;p&gt;机器学习模型众多，不存在所谓的最强模型，不同的数据，不同的问题适用 不同的模型。我们测试了 LASSO、SVM、增强型决策树、随机森林等几种 常见机器学习方法，最终选择用随机森林，主要是因为它结构简单、参数少 过拟合概率低，同时还具有非常强的样本外预测能力。&lt;/p&gt;

&lt;p&gt;机器选股模型省去了“因子筛选”、“因子加权”和“ZSCORE 转收益率 这三个步骤，直接通过随机森林做回归，由 alpha 因子来预测收益率。需要 说明的是，决策树本身也可以用来做变量筛选，但是我们并没有把这一步交 给机器，而是仍然保留了“因子 IC 检验”这个步骤，保证随机森林的输入 变量确确实实是符合我们传统意义的 alpha 因子;如果把很多没有选股效用 的因子混在一起作为输入变量，会导致数据噪音过大，产生“ Garbage in, Garbageout” 的问题，降低模型的预测能力。&lt;/p&gt;

&lt;p&gt;实证结果显示，和传统 alpha 因子 IC_IR 加权方法相比，随机森林模型得到 的多空组合收益率和稳健性都更高，处理 alpha 因子间信息重叠的效果要比 我们之前报告提出的线性方法好。&lt;/p&gt;

&lt;p&gt;更经济实用的方法是找到一个预测能力还不错的 ML 模型，多花时间去寻找能提供独立信息源的 alpha 因子，改进数据特征提取方法。&lt;/p&gt;

&lt;p&gt;因子选股研究通常采用月频调仓模式，但是 Alpha 因子的效用并非在未来一 个月均匀分布，而是呈现逐步衰减的形态，也就是说我们从月初获得的 alpha 要比月末获得的 alpha 高，持仓一个月不动的调仓方式在当月后半段资金利 用效率较低，有必要在 alpha 衰退之前调仓。&lt;/p&gt;
&lt;p&gt;因子的alpha衰减速度可以用其IC的半衰期度量，基本面因子、估值因子的 衰减速度较慢，例如 CFP_TTM 指标的半衰期长达四个月;而技术类指标的 衰减速度较快，CGO_3M 指标 11 天左右 IC 即衰减了一半。&lt;/p&gt;
&lt;p&gt;实证发现，不论是做主动量化还是做指数增强组合，周频调仓方式在交易成本较低的情况表现都明显优于月频调仓组合，但当单边交易成本达到 0.5% 时，高频调仓带来的 alpha 增量将无法覆盖高换手带来的冲击成本，有必要人为主动控制换手率。&lt;/p&gt;
&lt;p&gt;控制换手会降低组合的总体换手率，节约交易成本，但同时也会损耗 alpha 当交易成本较低时，后者大于前者;交易成本较高时，前者大于后者。我们 实证发现即使人为控制换手，使得周频组合换手率降至月频调仓组合的水平，在不同交易成本设臵下，周频组合的表现都要明显优于月频调仓组合。&lt;/p&gt;
&lt;p&gt;周频调仓除了可以提升组合收益，也可以分散交易，降低冲击成本，增加策 略资金容量。报告里的测试方法完全可以用作日频调仓，但需要注意的是，交易频率越高，策略对交易水平的要求越高，算法交易是非常有必要的辅助工具。&lt;/p&gt;

&lt;p&gt;报告下文实证测试了周频调仓的因子选股策略效果，其操作方式完全可以提升到日频，但需要 说明的是交易频率越高，对交易水平要求也越高，交易员要能保证成交均价稳定在某个市场价格附 近。因此能使用算法交易程序的私募和券商自营等机构在高频 alpha 策略执行层面占据明显优势， 而目前公募和保险机构普遍采用的基金经理下达交易指令、交易员按委托下单的方式里面人为 不确 定因素较多，交易越频繁，累积的不确定性越高。另外，我们这里直接把月频 alpha 因子拿来做周 频交易，但事实可能存在一些周频有效，但月频无效的高频 alpha 因子，需要再去单独寻找验证。&lt;/p&gt;

&lt;p&gt;Alpha 因子的效用并非在时间上均匀分布，而是会随着时间衰减，技术类因子的衰减速度会明 显快于基本面因子，因此投资者应该提高交易频率，在 alpha 衰退之前调仓。高频调仓会带来高换 手，在交易成本较高的情况的下有必要人为控制换手率，我们实证研究发现不论是做主动量化组合 还是做指数增强，即使周频调仓组合的换手率控制得和月频一致，周频组合的表现也更好。周频调 仓方式不仅可以获得更高收益，而且可以分散交易，降低冲击成本，提升策略资金容量。报告里的 测试方法可以进一步提升到日频，但是需要注意的是，交易频率越高，策略对交易水平的要求越高， 算法交易是非常有必要的辅助工具。&lt;/p&gt;

&lt;p&gt;如同“主题投资”和“行业投资”等是投资于拥有同一主题属性或行 业属性的一篮子股票一样，“因子投资”，顾名思义，是投资于具有 同一“因子”属性的一篮子股票。这里的因子可以是大/小盘、价值/成长这样的风格因 子，也可以是动量/反转这样的技术指标。因子投资可以投资于这些特定的对一篮子股票的收益和风险具有解 释力的属性(betas)，而非着力于选择个股(alpha)&lt;/p&gt;

&lt;h2 id=&quot;后记&quot;&gt;后记&lt;/h2&gt;

&lt;p&gt;总之学习金融的路程还很漫长。。。&lt;/p&gt;
</description>
        <pubDate>Fri, 04 Aug 2017 00:00:00 +0800</pubDate>
        <link>http://0.0.0.0:80/2017/08/04/east-financial-report/</link>
        <guid isPermaLink="true">http://0.0.0.0:80/2017/08/04/east-financial-report/</guid>
        
        
      </item>
    
      <item>
        <title>金融数据智能分析平台</title>
        <description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;#build&quot;&gt;感冒依旧没有好…&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;总结一下实习期间搭建的一个金融数据智能分析平台&lt;/p&gt;

&lt;p id=&quot;build&quot;&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;h2 id=&quot;正文&quot;&gt;正文&lt;/h2&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;blockquote&gt;1.	服务器端：&lt;/blockquote&gt;
&lt;li&gt;flask http://flask.pocoo.org/ &lt;/li&gt;
&lt;pre&gt;&lt;code&gt;轻量级的Python Web框架
&lt;/code&gt;&lt;/pre&gt;
&lt;li&gt;pandas http://pandas.pydata.org/ &lt;/li&gt;
&lt;pre&gt;&lt;code&gt;Python的数据结构和数据分析工具包，提供数据处理的Wrangling的功能
&lt;/code&gt;&lt;/pre&gt;
&lt;li&gt;sklearn http://scikit-learn.org/ &lt;/li&gt;
&lt;pre&gt;&lt;code&gt;非常流行的Python机器学习包，依赖于numpy，scipy和matplotlib
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;2.	客户端:&lt;/blockquote&gt;
&lt;li&gt;jquery&lt;/li&gt;
&lt;pre&gt;&lt;code&gt;reactjs http://facebook.github.io/react/ 
facebook开发的js UI框架，基于组件（component）而非mvc
&lt;/code&gt;&lt;/pre&gt;
&lt;li&gt;d3js https://d3js.org/ &lt;/li&gt;
&lt;pre&gt;&lt;code&gt;数据驱动的DOM操纵库，可以创建丰富的数据可视化呈现。
&lt;/code&gt;&lt;/pre&gt;
&lt;li&gt;echarts http://www.oschina.net/p/echarts &lt;/li&gt;
&lt;pre&gt;&lt;code&gt;百度开发的数据可视化库，基于canvas技术，功能丰富。实为中国开源项目的翘楚。
&lt;/code&gt;&lt;/pre&gt;
&lt;li&gt;bootstrap http://getbootstrap.com/ &lt;/li&gt;
&lt;pre&gt;&lt;code&gt;twitter开发的前端框架，非常流行。
&lt;/code&gt;&lt;/pre&gt;
&lt;li&gt;jquery datatables  http://www.datatables.net/ &lt;/li&gt;
&lt;pre&gt;&lt;code&gt;非常实用的基于jquery的表格控件
&lt;/code&gt;&lt;/pre&gt;
&lt;li&gt;bootstrap fielinput https://github.com/kartik-v/bootstrap-fileinput &lt;/li&gt;
&lt;pre&gt;&lt;code&gt;HTML5文件上传控件
&lt;/code&gt;&lt;/pre&gt;
&lt;li&gt;papaparse https://github.com/mholt/PapaParse &lt;/li&gt;
&lt;pre&gt;&lt;code&gt;CSV文件的JS解析
&lt;/code&gt;&lt;/pre&gt;
&lt;li&gt;requirejs http://www.requirejs.org/ &lt;/li&gt;
&lt;pre&gt;&lt;code&gt;JS 依赖管理
&lt;/code&gt;&lt;/pre&gt;
&lt;li&gt;select2  https://select2.github.io/ &lt;/li&gt;
&lt;pre&gt;&lt;code&gt;基于jquery的select控件
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;3.	开发构建工具&lt;/blockquote&gt;
&lt;li&gt;nodejs https://nodejs.org/en/ &lt;/li&gt;
&lt;li&gt;babel https://babeljs.io/ &lt;/li&gt;
&lt;p&gt;javascript的编译器，支持把ES6的代码转换成浏览器可执行的代码，这里主要是为了支持reactjs使用的jsx的编译。运行financial_dataplatform非常简单，下载github上的code后，建议安装anaconda2，所有的Python2.7依赖就都准备好了，进入financial_dataplatform/package目录，运行：python main.py
以下步骤在只有js源文件而没有lib文件夹情况下才需要进行，而github中含有所有需要的文件，所以下述命令都不需要进行。&lt;/p&gt;
&lt;p&gt;在只有js文件夹的情况下，因为react的js需要编译，需要运行如下的命令用babel进行js的转码才能运行，具体命令如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## install node first&amp;lt;/br&amp;gt;
## cd package/static&amp;lt;/br&amp;gt;
npm install -g babel-cli&amp;lt;/br&amp;gt;
npm install babel-preset-es2015 --save&amp;lt;/br&amp;gt;
npm install babel-preset-react --save&amp;lt;/br&amp;gt;
babel --presets es2015,react --watch js/ --out-dir lib/&amp;lt;/br&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;大家也可以参考package/static/package.json了解需要的依赖。有时间需要集成一个更简单的build脚本来做这些事情。生成的JS文件在lib目录下。当修改了js／文件夹下的js文件之后也需要执行上一条babel命令完成转码，然后在浏览器中键入 localhost:5000启动客户端。&lt;/p&gt;

&lt;blockquote&gt;4.	接下来介绍两部分功能：&lt;/blockquote&gt;
&lt;p&gt;数据上传用到了file input控件，数据表用了datatable控件。为了方便CSV文件直接存贮在本地文件系统中。后台用pandas对csv文件进行处理。前台用Rest API读取csv文件，然后用papaparse解析后，展现在数据表中。更好的做法是在后台用Python对CSV文件作解析。注意这里对上传的CSV文件有严格的要求，必须有首行的header，末尾不能有空行。&lt;/p&gt;
&lt;p&gt;有了数据后，就可以开始做分析了。首先我们看看可视化的分析。点击菜单Analysis／Visualization。可视化这一块的主要工作是从CSV的表结构数据，根据数据绑定，变形到echart的数据结构。因为echart并没有一个统一的数据模型，所以每一个类型的图表都需要有对应的数据变形的逻辑 。（代码 package/static/js/visualization ）现在主要的做了Pie，Bar，Line，Treemap，Scatter， Area这几种chart。现在用下来感觉echart优缺点都很明显，他提供的辅助功能很好，可以方便的增加辅助线，note，存贮为图形等。但是由于缺乏统一的数据模型扩展起来比较麻烦，接下来试用一下plotly，当然highchart是非常成熟的图表库。&lt;/p&gt;
&lt;p&gt;除了基于可视化的分析功能，还有机器学习的功能。分类的算法可以使用KNN，Bayes和SVM。聚类算法现在实现了Kmeans。回归实现了线性回归和逻辑回归。&lt;/p&gt;

&lt;blockquote&gt;5.	接下来可以进一步实现的功能：&lt;/blockquote&gt;
&lt;li&gt;数据源&lt;/li&gt;
&lt;p&gt;现在的数据源只有CSV文件和数据库，可以考虑更多的数据源支持，例如数据仓库，REST调用，流等等。&lt;/p&gt;
&lt;li&gt;数据模型&lt;/li&gt;
&lt;p&gt;现在的数据模型比较简单，就是pandas的dataframe或者一个简单的cvs的表结构。可以考虑引入数据库。另外还需要增加对层级数据（hierachical）的支持&lt;/p&gt;
&lt;li&gt;数据变形&lt;/li&gt;
&lt;p&gt;数据变形是数据分析的必要准备工作。业内有很多专注于数据准备的产品，例如paxata,trifacta。现有的平台没有任何的数据变形和准备的功能，其实pandas有非常丰富的data wrangling的功能，我希望能在这之上包装一个data wrangling的DSL，可以让用户快速的进行数据准备。&lt;/p&gt;
&lt;li&gt;可视化库&lt;/li&gt;
&lt;p&gt;Baidu的echart是非常优秀的可视化库，可是用于数据探索时，还不够好。希望能有一套类似ggplot的前端可视化库来使用。另外地图功能和层级化的图表也是数据分析常见的功能。&lt;/p&gt;
&lt;li&gt;仪表盘功能&lt;/li&gt;
&lt;p&gt;这个没有仪表盘功能，这个功能是数据分析软件的标配。pyxley似乎是个不错的选择，也和dataplay的架构一致（python，reactjs）。&lt;/p&gt;
&lt;li&gt;机器学习和预测&lt;/li&gt;
&lt;p&gt;现在实现了最简单的一些机器学习和深度学习的算法，我觉得方向应该是面向用户，变得更简单，用户只给出简单的选项，例如要预测的目标属性，和用于预测的属性，然后自动的选择算法。另外需要更方便的对算法进行扩展。未来可以进一步拓展GPU的支持。&lt;/p&gt;

&lt;h2 id=&quot;后记&quot;&gt;后记&lt;/h2&gt;

&lt;p&gt;下一篇介绍系统的数据库分析平台搭建方式。&lt;/p&gt;
</description>
        <pubDate>Wed, 26 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://0.0.0.0:80/2017/07/26/financial-dataplatform/</link>
        <guid isPermaLink="true">http://0.0.0.0:80/2017/07/26/financial-dataplatform/</guid>
        
        
      </item>
    
      <item>
        <title>Beta对冲</title>
        <description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;#build&quot;&gt;嗓子疼，快感冒了…&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;总结一下金融知识&lt;/p&gt;

&lt;p id=&quot;build&quot;&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;h2 id=&quot;正文&quot;&gt;正文&lt;/h2&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;p&gt;因子模型
因子模型是通过其他若干项资产回报的线性组合来解释一项资产回报的一种方式，因子模型的一般形式是：&lt;/p&gt;
&lt;p&gt;
\begin{align}\notag 
Y=α+β_{1}X_{1}+β_{2}X_{2}+...+β_{n}X_{n}
\end{align}
&lt;/p&gt;
&lt;blockquote&gt;什么是beta?&lt;/blockquote&gt;

&lt;p&gt;一项资产的beta是该资产收益率与其他资产收益率通过上述模型回归拟合的β。比如，我们用回归模型&lt;/p&gt;
&lt;p&gt;
\begin{align}\notag Y_{gzmt}=α+βX_{benchmark}Y_{gzmt}=α+βX_{benchmark}
\end{align}
&lt;/p&gt;
&lt;p&gt;来描述贵州茅台收益率相对于沪深300回归的ββ值，如果我们使用模型&lt;/p&gt;
&lt;p&gt;
\begin{align}\notag
Y_{gzmt}=α+β_{1}X_{benchmark}+β_{2}X_{wly}Y_{gzmt}=α+β_{1}X_{benchmark}+β_{2}X_{wly}
\end{align}
&lt;/p&gt;
&lt;p&gt;那么就会出现两个beta,一个是贵州茅台对沪深300的风险暴露，一个是贵州茅台对五粮液的风险暴露。

通常而言，betabeta更多地指该资产相对于基准指数的风险暴露，即只相对于市场基准的一元线性回归所得到的回归系数。&lt;/p&gt;

&lt;blockqoute&gt;
什么是对冲?
&amp;lt;/blockquote&amp;gt;
&lt;p&gt;如果我们确定我们的投资组合的回报与市场的关系如下面公式所示：&lt;/p&gt;
&lt;p&gt;
\begin{align}\notag
Y_{portfolio}=α+βX_{hs300}
\end{align}
&lt;/p&gt;
&lt;p&gt;
\begin{align}\notag
Y_{portfolio}=α+βX_{hs300}
\end{align}
&lt;/p&gt;
&lt;p&gt;于是，我们可以建立沪深300空头头寸来对冲市场风险，对冲的市值为−βV,如果我们持有多头组合的市值是V。因为我们多头组合的收益为α+βXhs300α+βXhs300,沪深300对冲空头的收益为−βXhs300−βXhs300,于是我们最终的收益为α+βXhs300−βXhs300=α+βXhs300−βXhs300=α,于是我们的收益来源只有αα，而与市场系统风险没有关系。
&lt;/p&gt;

&lt;blockquote&gt;风险暴露&lt;/blockquote&gt;

&lt;p&gt;一般而言，beta描述的是持有资产所承担的系统风险敞口这一概念。 如果一项资产相对沪深300基准指数具有较高的β暴露水平，那么在市场上涨时，它的表现将会很好，当市场下跌时，它表现很差。 高ββ对应于高系统风险（高市场风险），意味着你的投资更具有波动性。市场中性策略对于拥有大量现金池的机构（银行、保险、公募基金等）最具吸引力。&lt;/p&gt;

&lt;blockquote&gt;风险管理&lt;/blockquote&gt;

&lt;p&gt;减少因子风险暴露的过程称为风险管理。对冲是在实践中进行风险管理的最佳方式之一。

本文通过具体案例来了解如何做到市场风险对冲的，我们使用贵州茅台和基准沪深300来构建我们的投资组合，将沪深300的权重设为-β（由于持有基准空头头寸）。&lt;/p&gt;

```
	# 得到过去一年得到的alpha 和beta值
	start_date = '2014-01-01'
	end_date = '2015-01-01'
	asset = D.history_data('600519.SHA',start_date,end_date,fields=['close']).set_index('date')['close']
	benchmark = D.history_data('000300.SHA',start_date,end_date,fields=['close']).set_index('date')['close']
	r_a = asset.pct_change()[1:]
	r_b = benchmark.pct_change()[1:]
	X = r_b.values
	Y = r_a.values
	historical_alpha, historical_beta = linreg(X,Y)
	print('Asset Historical Estimate:')
	print('alpha: ' + str(historical_alpha))
	print('beta: ' + str(historical_beta))

	# 获取下一年的数据:
	start_date = '2015-01-01'
	end_date = '2015-06-01'
	asset = D.history_data('600519.SHA',start_date,end_date,fields=['close']).set_index('date')['close']
	benchmark = D.history_data('000300.SHA',start_date,end_date,fields=['close']).set_index('date')['close']
	asset.name = '600519.SHA'
	benchmark.name = '000300.SHA'
	# 重复前面的过程来计算alpha 和beta值
	r_a = asset.pct_change()[1:]
	r_b = benchmark.pct_change()[1:]
	X = r_b.values
	Y = r_a.values
	alpha, beta = linreg(X,Y)
	print('Asset Out of Sample Estimate:')
	print('alpha: ' + str(alpha))
	print('beta: ' + str(beta))

	# 构建对冲投资组合来计算alpha、beta
	portfolio = -1*historical_beta*r_b + r_a
	P = portfolio.values
	alpha, beta = linreg(X,P)
	print('Portfolio Out of Sample:')
	print ('alpha: ' + str(alpha))
	print ('beta: ' + str(beta))


	# 绘制图形
	portfolio.name = &quot;600519.SHA + Hedge&quot;
	portfolio.plot(alpha=0.9,figsize=[9,6])
	r_a.plot(alpha=0.5);
	r_b.plot(alpha=0.5)
	plt.ylabel(&quot;Daily Return&quot;)
	plt.legend();



	Asset Historical Estimate:
	alpha: 0.00116253939056
	beta: 0.672934653004
	Asset Out of Sample Estimate:
	alpha: 0.00020366206079
	beta: 0.866552969103
	Portfolio Out of Sample:
	alpha: 0.000203662008879
	beta: 0.193618313006
```

&lt;p&gt;从上图可以看出，对冲后的收益降低了，但波动性也降低了。历史估计出的贝塔值在样本外的一年中是有效的，将资产的贝塔值0.673通过对冲降低到了0.193，也就是说降低了2/3，这样的对冲效果是比较明显的，而且也反映出历史的贝塔值是有效的，当然，要做到更好的效果，可以采取滚动估计贝塔的方法。&lt;/p&gt;
&lt;p&gt;市场中性策略是指同时构建多头和空头头寸以对冲市场风险，在市场不论上涨或者下跌的环境下均能获得稳定收益的一种投资策略，市场中性策略主要依据统计套利的量化分析。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(1)阿尔法套利：做多具有阿尔法值的证券产品，做空指数期货，实现回避系统性风险下的超越市场指数的阿尔法收益。&lt;/li&gt;

&lt;li&gt;(2)贝塔套利：期指市场上做空，在股票市场上构建拟合300指数的成份股，赚取其中的价差，这种被动型的套利。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;什么是市盈率&lt;/blockquote&gt;
&lt;p&gt;市盈率是衡量股价高低和企业盈利能力的一个重要指标。由于市盈率把股价和企业盈利能力结合起来，其水平高低更真实地反映了股票价格的高低。例如，股价同为50元的两只股票，其每股收益分别为5元和1元，则其市盈率分别是10倍和50倍，也就是说具当前的实际价格水平相差5倍。若企业盈利能力不变，这说明投资者以同样50元价格购买的两种股票，要分别在10年和50年以后才能从企业盈利中收回投资。因此市盈率倍数可以简单地理解为要收回投资，最少需要多少年，很明显市盈率越低，越具有吸引力。&lt;/p&gt;

&lt;p&gt;通常，此分析是基于历史数据，而对历史风险暴露的估计可能会影响未来的风险暴露。 因此，计算因子风险暴露是不够的。 你必须对风险暴露保持信心，并明白对风险暴露的建模是否合理。&lt;/p&gt;

&lt;p&gt;运用多因子模型计算因子风险暴露
,我们可以运用多因子模型分析一个组合中风险和收益的来源，多因子模型对收益的分解如下：&lt;p&gt;

&lt;p&gt;
\begin{align}\notag
R_{i}=a_{i}+b_{i1}F_{1}+b_{i2}F_{2}+...+b_{iK}F_{K}+ϵ_{i}
\end{align}

&lt;/p&gt;

&lt;p&gt;通过对历史收益率进行建模，我们可以分析出收益中有多少是来自因子收益率，有多少来自资产特质波动（ϵϵ）。 我们也可以研究投资组合所面临的风险来源，即投资组合的因子暴露。&lt;/p&gt;

&lt;p&gt;在风险分析中，我们经常对主动回报（相对于基准的回报）和主动风险（主动回报的标准差，也称为跟踪误差或跟踪风险）进行建模。&lt;/p&gt;

&lt;p&gt;例如，我们可计算到一个因子对主动风险的边际贡献——FMCAR。 对于因子jj，表示为：&lt;/p&gt;

&lt;p&gt;
\begin{align}\notag
FMCAR_{j}=\frac{bj\sum_{i=1}^{k}{b_{i}cov(F_{j},F_{i})}}{(Active Risk)^2}
\end{align}
&lt;/p&gt;
&lt;p&gt;bj表示组合对因子j的风险暴露,bi表示组合对因子i的风险暴露,K表示一共K个因子。FMCARj这项指标这告诉我们，假设其他条件不变，暴露在因子j下我们增加了多少风险。&lt;/p&gt;

&lt;p&gt;下面我们运用多因素模型和线性回归工具来计算某只股票的回报率相对于这些因子的风险暴露程度。我们以某个资产组合的主动收益作为被解释变量，对因子做回归，一个因子对主动收益贡献越大，那么这个资产组合的主动收益对于该因子的暴露程度也越高。&lt;/p&gt;
```
	# 我们以5只股票的组合（portfolio）举例
	instruments = D.instruments()[:5]
	Stock_matrix = D.history_data(instruments,start_date,end_date,fields=['close'])
	Stock_matrix = pd.pivot_table(Stock_matrix,values='close',index=['date'],columns=['instrument'])
	portfolio = Stock_matrix.pct_change()[1:]
	# 组合的每日收益率（等权重组合）
	R = np.mean(portfolio, axis=1)
	# 基准收益率
	bench = D.history_data('000300.SHA',start_date, end_date, fields=['close']).set_index('date')['close'].pct_change()[1:]
	# 主动收益率
	active = R - bench
	# 建立一个常数项，为下文回归做准备
	constant = pd.TimeSeries(np.ones(len(active.index)), index=active.index)
	df = pd.DataFrame({'R': active,
	'F1': SMB,
	'F2': HML,
	'Constant': constant})
	# 删除含有缺失值的行
	df = df.dropna()
	#线性回归并获取回归系数
	b1, b2 = regression.linear_model.OLS(df['R'], df[['F1', 'F2']]).fit().params
	# 因子对于主动收益的敏感性（即因子暴露）
	print('Sensitivities of active returns to factors:\nSMB: %f\nHML: %f' %  (b1, b2))
	Sensitivities of active returns to factors:
	SMB: 0.430179
	HML: -0.104828
	利用前文给的公式，计算因子对主动收益风险平方的边际贡献（factors' marginal contributions to active risk squared，FMCAR ）

	# 计算因子风险贡献
	F1 = df['F1']
	F2 = df['F2']
	cov = np.cov(F1, F2)
	ar_squared = (active.std())**2
	fmcar1 = (b1*(b2*cov[0,1] + b1*cov[0,0]))/ar_squared
	fmcar2 = (b2*(b1*cov[0,1] + b2*cov[1,1]))/ar_squared
	print('SMB Risk Contribution:', fmcar1)
	print('HML Risk Contribution:', fmcar2)
	SMB Risk Contribution: 0.145330519205
	HML Risk Contribution: 0.0321851978612
```
&lt;p&gt;余下的风险可以归结于一些特有的风险因素，即我们没有加入模型的因子或者资产组合本身独有的某种风险。 通常我们会关注一下对这些因子的风险暴露随时间如何变化。让我们rolling一下～&lt;/p&gt;
```
	# 计算滚动的beta
	model = pd.stats.ols.MovingOLS(y = df['R'], x=df[['F1', 'F2']], 
	window_type='rolling', 
	window=100)   
	rolling_parameter_estimates = model.beta
	rolling_parameter_estimates.plot()
	plt.title('Computed Betas');
	plt.legend(['F1 Beta', 'F2 Beta', 'Intercept']);
```
现在我们来看看FMCAR是如何随时间变化的
```
	# 计算方差协方差
	# 去除有缺省值的日期，从有实际有效值的日期开始
	covariances = pd.rolling_cov(df[['F1', 'F2']], window=100)[99:]
	# 计算主动风险
	active_risk_squared = pd.rolling_std(active, window = 100)[99:]**2
	# 计算beta
	betas = rolling_parameter_estimates[['F1', 'F2']]

	# 新建一个空的dataframe
	FMCAR = pd.DataFrame(index=betas.index, columns=betas.columns)

	# 每个因子循环
	for factor in betas.columns:
	# 每一天循环
	for t in betas.index:
	# 求beta与协方差之积的和，见公式
	s = np.sum(betas.loc[t] * covariances[t][factor])
	# 获取beta
	b = betas.loc[t][factor]
	# 获取主动风险
	AR = active_risk_squared.loc[t]
	# 估计当天的FMCAR
	FMCAR[factor][t] = b * s / AR
```
&lt;p&gt;了解历史数据中组合对各个因子的暴露程度是很有趣的，但只有将它用在对未来预测上时，它才有用武之地。但我们不是总能够放心地认为未来的情况与现在相同，由于随时间会变化，对风险暴露程度取平均值也很容易出现问题。我们可以给均值加上一个置信区间，但只有当其分布是正态分布或者表现很稳健才行。我们来看看Jarque-Bera测验的结果。&lt;/p&gt;
```
	from statsmodels.stats.stattools import jarque_bera
	_, pvalue1, _, _ = jarque_bera(FMCAR['F1'].dropna().values)
	_, pvalue2, _, _ = jarque_bera(FMCAR['F2'].dropna().values)

	&lt;p&gt;print('p-value F1_FMCAR is normally distributed', pvalue1)
	print('p-value F2_FMCAR is normally distributed', pvalue2)
	p-value F1_FMCAR is normally distributed 4.05960522776e-08
	p-value F2_FMCAR is normally distributed 0.000299975153613
```
&lt;p&gt;p_value显示我们可以显著的拒绝其为正态分布，可见对于未来这些因素会导致多少风险暴露是很难估计的，所以在使用这些统计模型去估计风险暴露并以此为依据来对冲是需要万分小心的。&lt;/p&gt;

## 后记

没有后记
&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/blockqoute&gt;
</description>
        <pubDate>Wed, 19 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://0.0.0.0:80/2017/07/19/beta/</link>
        <guid isPermaLink="true">http://0.0.0.0:80/2017/07/19/beta/</guid>
        
        
      </item>
    
      <item>
        <title>PYTHON多进程总结</title>
        <description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;#build&quot;&gt;这是一个简单而又痛苦的开始…&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;继续总结python多进程的内容。&lt;/p&gt;

&lt;p id=&quot;build&quot;&gt;&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;######正文
&lt;br /&gt;
由于GIL的原因，在python中涉及到多线程处理问题都需要使用多进程。
&lt;br /&gt;
Unix/Linux操作系统提供了一个fork()系统调用，它非常特殊。普通的函数调用，调用一次，返回一次，但是fork()调用一次，返回两次，因为操作系统自动把当前进程（称为父进程）复制了一份（称为子进程），然后，分别在父进程和子进程内返回。
&lt;br /&gt;
子进程永远返回0，而父进程返回子进程的ID。这样做的理由是，一个父进程可以fork出很多子进程，所以，父进程要记下每个子进程的ID，而子进程只需要调用getppid()就可以拿到父进程的ID。
&lt;br /&gt;
Python的os模块封装了常见的系统调用，其中就包括fork，可以在Python程序中轻松创建子进程。
&lt;br /&gt;
由于Windows没有fork调用，上面的代码在Windows上无法运行。由于Mac系统是基于BSD（Unix的一种）内核，所以，在Mac下运行是没有问题的，推荐大家用Mac学Python！
&lt;br /&gt;
有了fork调用，一个进程在接到新任务时就可以复制出一个子进程来处理新任务，常见的Apache服务器就是由父进程监听端口，每当有新的http请求时，就fork出子进程来处理新的http请求。
&lt;br /&gt;
如果你打算编写多进程的服务程序，Unix/Linux无疑是正确的选择。由于Windows没有fork调用，难道在Windows上无法用Python编写多进程的程序？&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;由于Python是跨平台的，自然也应该提供一个跨平台的多进程支持。multiprocessing模块就是跨平台版本的多进程模块。
&lt;br /&gt;
创建子进程时，只需要传入一个执行函数和函数的参数，创建一个Process实例，用start()方法启动，这样创建进程比fork()还要简单。join()方法可以等待子进程结束后再继续往下运行，通常用于进程间的同步。
&lt;br /&gt;
如果要启动大量的子进程，可以用进程池的方式批量创建子进程。对Pool对象调用join()方法会等待所有子进程执行完毕，调用join()之前必须先调用close()，调用close()之后就不能继续添加新的Process了。
&lt;br /&gt;
Process之间肯定是需要通信的，操作系统提供了很多机制来实现进程间的通信。Python的multiprocessing模块包装了底层的机制，提供了Queue、Pipes等多种方式来交换数据。
&lt;br /&gt;
在Unix/Linux下，multiprocessing模块封装了fork()调用，使我们不需要关注fork()的细节。由于Windows没有fork调用，因此，multiprocessing需要“模拟”出fork的效果，父进程所有Python对象都必须通过pickle序列化再传到子进程去，所有，如果multiprocessing在Windows下调用失败了，要先考虑是不是pickle失败了。
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;######代码字段&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import multiprocessing
import time

def worker(interval):
    n = 5
    while n &amp;gt; 0:
        print(&quot;The time is {0}&quot;.format(time.ctime()))
        time.sleep(interval)
        n -= 1

if __name__ == &quot;__main__&quot;:
    p = multiprocessing.Process(target = worker, args = (3,))
    p.start()
    print(&quot;p.pid:&quot;, p.pid)
    print(&quot;p.name:&quot;, p.name)
    print(&quot;p.is_alive:&quot;, p.is_alive())
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;p.pid: 4548
p.name: Process-1
p.is_alive: True
The time is Mon Jul 17 15:27:33 2017
The time is Mon Jul 17 15:27:36 2017
The time is Mon Jul 17 15:27:39 2017
The time is Mon Jul 17 15:27:42 2017
The time is Mon Jul 17 15:27:45 2017
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import multiprocessing
import time

def worker_1(interval):
    print(&quot;worker_1&quot;)
    time.sleep(interval)
    print(&quot;end worker_1&quot;)

def worker_2(interval):
    print(&quot;worker_2&quot;)
    time.sleep(interval)
    print(&quot;end worker_2&quot;)

def worker_3(interval):
    print(&quot;worker_3&quot;)
    time.sleep(interval)
    print(&quot;end worker_3&quot;)

if __name__ == &quot;__main__&quot;:
    p1 = multiprocessing.Process(target = worker_1, args = (2,))
    p2 = multiprocessing.Process(target = worker_2, args = (3,))
    p3 = multiprocessing.Process(target = worker_3, args = (4,))

    p1.start()
    p2.start()
    p3.start()

    print(&quot;The number of CPU is:&quot; + str(multiprocessing.cpu_count()))
    for p in multiprocessing.active_children():
        print(&quot;child   p.name:&quot; + p.name + &quot;\tp.id&quot; + str(p.pid))
    print(&quot;END!!!!!!!!!!!!!!!!!&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;The number of CPU is:4
child   p.name:Process-4	p.id4560
child   p.name:Process-3	p.id4559
child   p.name:Process-2	p.id4558
END!!!!!!!!!!!!!!!!!
worker_2
worker_1
worker_3
end worker_1
end worker_2
end worker_3
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import multiprocessing
import time

class ClockProcess(multiprocessing.Process):
    def __init__(self, interval):
        multiprocessing.Process.__init__(self)
        self.interval = interval

    def run(self):
        n = 5
        while n &amp;gt; 0:
            print(&quot;the time is {0}&quot;.format(time.ctime()))
            time.sleep(self.interval)
            n -= 1

if __name__ == '__main__':
    p = ClockProcess(3)
    p.start()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;the time is Mon Jul 17 15:29:14 2017
the time is Mon Jul 17 15:29:17 2017
the time is Mon Jul 17 15:29:20 2017
the time is Mon Jul 17 15:29:23 2017
the time is Mon Jul 17 15:29:26 2017
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import multiprocessing
import time

def worker(interval):
    print(&quot;work start:{0}&quot;.format(time.ctime()));
    time.sleep(interval)
    print(&quot;work end:{0}&quot;.format(time.ctime()));

if __name__ == &quot;__main__&quot;:
    p = multiprocessing.Process(target = worker, args = (3,))
    p.start()
    print(&quot;end!&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;end!
work start:Mon Jul 17 15:30:40 2017
work end:Mon Jul 17 15:30:43 2017
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import multiprocessing
import time

def worker(interval):
    print(&quot;work start:{0}&quot;.format(time.ctime()));
    time.sleep(interval)
    print(&quot;work end:{0}&quot;.format(time.ctime()));

if __name__ == &quot;__main__&quot;:
    p = multiprocessing.Process(target = worker, args = (3,))
    p.daemon = True
    p.start()
    print(&quot;end!&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;end!
work start:Mon Jul 17 15:31:36 2017
work end:Mon Jul 17 15:31:39 2017
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import multiprocessing
import time

def worker(interval):
    print(&quot;work start:{0}&quot;.format(time.ctime()));
    time.sleep(interval)
    print(&quot;work end:{0}&quot;.format(time.ctime()));

if __name__ == &quot;__main__&quot;:
    p = multiprocessing.Process(target = worker, args = (3,))
    p.daemon = True
    p.start()
    p.join()
    print(&quot;end!&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;work start:Mon Jul 17 15:33:05 2017
work end:Mon Jul 17 15:33:09 2017
end!
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import multiprocessing
import sys

def worker_with(lock, f):
    with lock:
        fs = open(f, 'a+')
        n = 10
        while n &amp;gt; 1:
            fs.write(&quot;Lockd acquired via with\n&quot;)
            n -= 1
        fs.close()
        
def worker_no_with(lock, f):
    lock.acquire()
    try:
        fs = open(f, 'a+')
        n = 10
        while n &amp;gt; 1:
            fs.write(&quot;Lock acquired directly\n&quot;)
            n -= 1
        fs.close()
    finally:
        lock.release()
    
if __name__ == &quot;__main__&quot;:
    lock = multiprocessing.Lock()
    f = &quot;file.txt&quot;
    w = multiprocessing.Process(target = worker_with, args=(lock, f))
    nw = multiprocessing.Process(target = worker_no_with, args=(lock, f))
    w.start()
    nw.start()
    print(&quot;end&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import multiprocessing
import time

def worker(s, i):
    s.acquire()
    print(multiprocessing.current_process().name + &quot;acquire&quot;);
    time.sleep(i)
    print(multiprocessing.current_process().name + &quot;release\n&quot;);
    s.release()

if __name__ == &quot;__main__&quot;:
    s = multiprocessing.Semaphore(2)
    for i in range(5):
        p = multiprocessing.Process(target = worker, args=(s, i*2))
        p.start()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Process-11acquire
Process-12acquire
Process-11release

Process-13acquire
Process-12release

Process-14acquire
Process-13release

Process-15acquire
Process-14release

Process-15release
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import multiprocessing
import time

def wait_for_event(e):
    print(&quot;wait_for_event: starting&quot;)
    e.wait()
    print(&quot;wairt_for_event: e.is_set()-&amp;gt;&quot; + str(e.is_set()))

def wait_for_event_timeout(e, t):
    print(&quot;wait_for_event_timeout:starting&quot;)
    e.wait(t)
    print(&quot;wait_for_event_timeout:e.is_set-&amp;gt;&quot; + str(e.is_set()))

if __name__ == &quot;__main__&quot;:
    e = multiprocessing.Event()
    w1 = multiprocessing.Process(name = &quot;block&quot;,
            target = wait_for_event,
            args = (e,))

    w2 = multiprocessing.Process(name = &quot;non-block&quot;,
            target = wait_for_event_timeout,
            args = (e, 2))
    w1.start()
    w2.start()

    time.sleep(3)

    e.set()
    print(&quot;main: event is set&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;wait_for_event: starting
wait_for_event_timeout:starting
wait_for_event_timeout:e.is_set-&amp;gt;False
wairt_for_event: e.is_set()-&amp;gt;True
main: event is set
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import multiprocessing

def writer_proc(q):      
    try:         
        q.put(1, block = False) 
    except:         
        pass   

def reader_proc(q):      
    try:         
        print(q.get(block = False))
    except:         
        pass

if __name__ == &quot;__main__&quot;:
    q = multiprocessing.Queue()
    writer = multiprocessing.Process(target=writer_proc, args=(q,))  
    writer.start()   

    reader = multiprocessing.Process(target=reader_proc, args=(q,))  
    reader.start()  

    reader.join()  
    writer.join()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;1
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import multiprocessing
import time

def proc1(pipe):
    while True:
        for i in arrange(0,10000):
            print(&quot;send: %s&quot; %(i))
            pipe.send(i)
            time.sleep(1)

def proc2(pipe):
    while True:
        print(&quot;proc2 rev:&quot;, pipe.recv())
        time.sleep(1)

def proc3(pipe):
    while True:
        print(&quot;PROC3 rev:&quot;, pipe.recv())
        time.sleep(1)

if __name__ == &quot;__main__&quot;:
    pipe = multiprocessing.Pipe()
    p1 = multiprocessing.Process(target=proc1, args=(pipe[0],))
    p2 = multiprocessing.Process(target=proc2, args=(pipe[1],))
    #p3 = multiprocessing.Process(target=proc3, args=(pipe[1],))

    p1.start()
    p2.start()
    #p3.start()

    p1.join()
    p2.join()
    #p3.join()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import multiprocessing
import time

def func(msg):
    print(&quot;msg:&quot;, msg)
    time.sleep(3)
    print(&quot;end&quot;)

if __name__ == &quot;__main__&quot;:
    pool = multiprocessing.Pool(processes = 3)
    for i in xrange(4):
        msg = &quot;hello %d&quot; %(i)
        pool.apply_async(func, (msg, ))   #维持执行的进程总数为processes，当一个进程执行完毕后会添加新的进程进去

    print(&quot;Mark~ Mark~ Mark~~~~~~~~~~~~~~~~~~~~~~&quot;)
    pool.close()
    pool.join()   #调用join之前，先调用close函数，否则会出错。执行完close后不会有新的进程加入到pool,join函数等待所有子进程结束
    print(&quot;Sub-process(es) done.&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import multiprocessing
import time

def func(msg):
    print(&quot;msg:&quot;, msg)
    time.sleep(3)
    print(&quot;end&quot;)

if __name__ == &quot;__main__&quot;:
    pool = multiprocessing.Pool(processes = 3)
    for i in range(0,3):
        msg = &quot;hello %d&quot; %(i)
        pool.apply(func, (msg, ))   #维持执行的进程总数为processes，当一个进程执行完毕后会添加新的进程进去

    print(&quot;Mark~ Mark~ Mark~~~~~~~~~~~~~~~~~~~~~~&quot;)
    pool.close()
    pool.join()   #调用join之前，先调用close函数，否则会出错。执行完close后不会有新的进程加入到pool,join函数等待所有子进程结束
    print(&quot;Sub-process(es) done.&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;msg: hello 0
end
msg: hello 1
end
msg: hello 2
end
Mark~ Mark~ Mark~~~~~~~~~~~~~~~~~~~~~~
Sub-process(es) done.
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import multiprocessing
import time

def func(msg):
    print(&quot;msg:&quot;, msg)
    time.sleep(3)
    print(&quot;end&quot;)
    return &quot;done&quot; + msg

if __name__ == &quot;__main__&quot;:
    pool = multiprocessing.Pool(processes=4)
    result = []
    for i in range(0,3):
        msg = &quot;hello %d&quot; %(i)
        result.append(pool.apply_async(func, (msg, )))
    pool.close()
    pool.join()
    for res in result:
        print(&quot;:::&quot;, res.get())
    print(&quot;Sub-process(es) done.&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;msg: hello 1
msg: hello 0
msg: hello 2
end
end
end
::: donehello 0
::: donehello 1
::: donehello 2
Sub-process(es) done.


import multiprocessing
import os, time, random

def Lee():
    print(&quot;\nRun task Lee-%s&quot; %(os.getpid())) #os.getpid()获取当前的进程的ID
    start = time.time()
    time.sleep(random.random() * 10) #random.random()随机生成0-1之间的小数
    end = time.time()
    print('Task Lee, runs %0.2f seconds.' %(end - start))

def Marlon():
    print(&quot;\nRun task Marlon-%s&quot; %(os.getpid()))
    start = time.time()
    time.sleep(random.random() * 40)
    end=time.time()
    print('Task Marlon runs %0.2f seconds.' %(end - start))

def Allen():
    print(&quot;\nRun task Allen-%s&quot; %(os.getpid()))
    start = time.time()
    time.sleep(random.random() * 30)
    end = time.time()
    print('Task Allen runs %0.2f seconds.' %(end - start))

def Frank():
    print(&quot;\nRun task Frank-%s&quot; %(os.getpid()))
    start = time.time()
    time.sleep(random.random() * 20)
    end = time.time()
    print('Task Frank runs %0.2f seconds.' %(end - start))
        
if __name__=='__main__':
    function_list=  [Lee, Marlon, Allen, Frank] 
    print(&quot;parent process %s&quot; %(os.getpid()))

pool=multiprocessing.Pool(4)
for func in function_list:
    pool.apply_async(func)     #Pool执行函数，apply执行函数,当有一个进程执行完毕后，会添加一个新的进程到pool中

print('Waiting for all subprocesses done...')
pool.close()
pool.join()    #调用join之前，一定要先调用close() 函数，否则会出错, close()执行后不会有新的进程加入到pool,join函数等待素有子进程结束
print('All subprocesses done.')
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;######后记&lt;/p&gt;

&lt;p&gt;python多进程的具体效果还是需要继续尝试。&lt;/p&gt;
</description>
        <pubDate>Mon, 17 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://0.0.0.0:80/2017/07/17/mulitiporcess/</link>
        <guid isPermaLink="true">http://0.0.0.0:80/2017/07/17/mulitiporcess/</guid>
        
        
      </item>
    
      <item>
        <title>何谓影子银行？</title>
        <description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;#build&quot;&gt;这是一个简单而又痛苦的开始…&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;很久之前就学习了python但是一直没有做一个系统性的总结，最近开了博客就总结下。&lt;/p&gt;

&lt;p id=&quot;build&quot;&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;h2 id=&quot;正文&quot;&gt;正文&lt;/h2&gt;

&lt;p&gt;&quot;影子银行”，正如其名，就像影子一样模仿着银行的一举一动，但却又没有具体的形体。对于影子银行，并没有一个放之四海而皆准的定义。
&lt;/p&gt;
&lt;p&gt;
国际组织金融稳定委员会(Financial Stability Board)在2011年4月的一份报告中将其定义为“正常银行监管系统之外作为信用中介而运行的机构或者交易行为” （“credit intermediation involving entities and activities (fully or partially) outside the regular banking system”）然而，Stijn Claessens 和 Lev Ratnovski两位学者并不认同这个定义，他们认为，金融稳定委员会的定义一方面“误伤”了对冲基金、资产管理公司等受到一定程度监管、一般不认为是“影子银行”的金融机构；另一方面，一些国家的银行本身也在开展类似影子银行的业务，例如资产证券化、回购业务等。尽管定义上有差异，但大方向上，只要看到两点特征，就可以大致称之为“影子银行”：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1. 从事类似银行的业务；&lt;/li&gt;
&lt;li&gt;2. 游离于银行监管体系外。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
--银行的业务，万变不离其宗，无非就是在时间和空间的维度倒腾钱，把未来的钱倒腾到现在用，把通过吸存来取得的钱用于放贷用。这样的业务模式就会产生最致命的一点风险：期限错配（Maturity Mismatch）。银行吸收了大量的短期存款，储户随时有可能要求取款，但却要用这样的短期存款去支撑长期的放贷，这样长短期限的差异，就可能导致银行长期贷款没收回来，却要应对迫在眉睫的取款需求。这也就意味着，银行不可能将全部存款都用于长期放贷，必须留出一部分准备金用于应对取款，否则就可能导致“钱荒”。钱荒不是银行真的资不抵债了，而是缺乏流动性资金，储户担心不能随时取回存款，于是争先恐后冲向银行，加剧钱荒，所以人们说银行挤兑是一种“自我实现的预言”。除了上面所说的流动性风险之外，银行业务还产生另外一种风险，系统性风险。当银行和其他机构之间互负债务债权关系，或者互相持有对方的产品时，一家机构的的违约，就可能导致与之联系的其他机构受到冲击，导致危机在系统中蔓延。
&lt;/p&gt;
&lt;p&gt;
“影子银行”：影子银行的业务，也是在拿时间来变戏法。举个例子：有种很传统的资产证券化产品，叫做资产支持证券(Asset Backed Security),就是将未来的现金流打包起来放到现在卖。我做小生意，一年能赚一万块，五年有五万块入账，那么资产支持证券的发行者就可以找到我说：“给你四万块，未来五年的现金流都流到我口袋里好了”，这就是用把未来的预期收益一下子挪到现在来买卖。而发行者可以把买回来的收益权打包成证券，找到其他的投资者，你五块我十块，购买这样的证券并许诺投资回报。这样的套路，类似于银行面向公众吸收存款，发放贷款，赚取存贷款利息差。以资产支持证券这种基本款的产品为蓝本，还可以衍生出很多其他的变体，例如抵押贷款证券(Mortgage Backed Security),这就是讲将未来贷款的还款现金流打包成证券来发行。 甚至连投资这类证券的预期收益，也可以继续打包成资产，在上面一层一层叠上去。也就是说，不仅做生意的预期收益可以用于作为资产来做成证券化产品，就连投资证券化产品的收益，也可以再次打包成证券。不管怎么挪，期限错配问题和随之而来的流动性风险依然存在。&lt;/p&gt;

&lt;p&gt;以美国次贷危机为例，抵押贷款证券的收益来源于贷款买房者在未来的还款，当这笔还款落空的时候，就无法向投资者支付投资收益。这就类似于银行的长期贷款出现了坏账。然而，银行有了一笔坏账，还可以用自有资金去满足偿付的需求，而资产证券化产品则缺乏这样一个安全垫。（这也就是为什么后来的多德弗兰克法案强调发行者自己持有一部分产品，目的就是要像银行的准备金一样，提供吸收违约影响的缓冲区）。流动性风险依然存在，系统性风险还更高了。银行贷款毕竟还不能轻而易举地来回倒手，而证券产品可以很灵活地来回买卖。而且，一家机构的资产，很有可能被打包成产品，为另一家机构所持有，这就将大家都捆成了一条绳上的蚂蚱。风险并没有减少，但监管却少了，没有类似于准备金之类的强制性要求，也没有充足的信息披露，这就是为什么人们说起“影子银行”谈虎色变的原因之一。--以上举了金融衍生品的例子&lt;/p&gt;

&lt;p&gt;但影子银行的具体表现形式远不限于此。说一个东西是不是影子银行，寻本溯源，还是要把握一开始说的两点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1. 从事类似银行的业务；&lt;/li&gt;
&lt;li&gt;2. 游离于银行监管体系外。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这样说来，经营民间借贷的地下钱庄、小额贷款公司，担保公司等可以是影子银行；理财产品和信托业务，可以是影子银行。影子银行不一定是多么高大上的金融创新，有一种“影子银行”已经存在了几百上千年：当铺。典当，不就是一种原始的抵押贷款嘛。--影子银行未必是坏的，它能提高资金配置的效率，降低获得资金的门槛。举个例子：在存在利率管制的情况下，银行无论是贷给大企业还是小企业，赚取的贷款利息不会有太大差别，但两者的风险和管理成本却有天壤之别。在不允许银行对两者分别制定不同利息的情况下，您说，银行会偏好向谁贷款呢？影子银行，则能够突破这样的限制，给风险水平不同的贷款定下不同的利息水平，这就是一种对分配效率的改善。
&lt;/p&gt;
&lt;p&gt;–参考文献：Simin Gao &amp;amp; Qianyu Wang, Chasing the Shadow in Different Worlds: Shadow Banking and its Regulation in the U.S. and China, Manchester Journal of International Economic Law , 2016 , 11 (3) :421-458&lt;/p&gt;

&lt;p&gt;作者：王瑞恩
链接：https://www.zhihu.com/question/19594906/answer/198995627
来源：知乎&lt;/p&gt;

&lt;p&gt;影子银行大致可以说是不通过银行直接发放的贷款。
具体包括：1、投资于企业贷款资产的银行理财产品。一般是投资于高信用等级企业贷款资产，比如大型央企贷款或者应收账款。2、房地产信托、房地产私募。向个人及机构投资者募集资金发放，这是近两年房地产公司的主要融资手段，包括万科恒大等龙头房企都广泛使用。3、债权类信托、私募基金，以及附加回购协议的各类信托、私募基金。投资方向可以说是千奇百怪，矿产资源类企业是比较常见的，还出现了艺术品、红酒等等。4、近年来如雨后春笋涌现的小额贷款公司、担保公司。5、民间集资、私人借贷。如沿海地区常见的所谓“标会”的集资借贷。&lt;/p&gt;

&lt;p&gt;作者：garhom
链接：https://www.zhihu.com/question/19594906/answer/15199988
来源：知乎&lt;/p&gt;

&lt;h2 id=&quot;后记&quot;&gt;后记&lt;/h2&gt;

&lt;p&gt;看到知乎上关于影子银行的讨论，觉得很有趣，就搬过来总结下。&lt;/p&gt;
</description>
        <pubDate>Sun, 16 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://0.0.0.0:80/2017/07/16/shadowbank/</link>
        <guid isPermaLink="true">http://0.0.0.0:80/2017/07/16/shadowbank/</guid>
        
        
      </item>
    
      <item>
        <title>为什么在执行八皇后程序的时候python比c++慢那么多</title>
        <description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;#build&quot;&gt;这是一个简单而又痛苦的开始…&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;很久之前就学习了python但是一直没有做一个系统性的总结，最近开了博客就总结下。&lt;/p&gt;

&lt;p id=&quot;build&quot;&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;h2 id=&quot;正文&quot;&gt;正文&lt;/h2&gt;

&lt;p&gt;这个八皇后的DFS，我的C++代码在不加某些评估性剪枝的情况下对15需要算18s左右（开O2大约8.6秒），但是可以确定的是你的解决方案里用了循环与递归。接下来需要分析的无非是Python慢在哪个细节，以及能否改进的问题。下面是两段用来测试的代码，首先是Python的：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import time

def calc(n, i=0, cols=0, diags=0, trans=0):
    if i == n:
        return 1
    else:
        rt = 0
        for j in range(n):
            col = 1 &amp;lt;&amp;lt; j
            diag = 1 &amp;lt;&amp;lt; (i - j + n - 1)
            tran = 1 &amp;lt;&amp;lt; (i + j)
            if (col &amp;amp; cols) == 0 and (diag &amp;amp; diags) == 0 and (tran &amp;amp; trans) == 0:
                rt += calc(n, i+1, cols | col, diags | diag, trans | tran)
        return rt

if __name__ == '__main__':
    t = time.time()
    print(calc(13))
    print(time.time() - t)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以及C++代码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#include &amp;lt;chrono&amp;gt;
#include &amp;lt;iostream&amp;gt;

using namespace std;

long calc(int n, int i = 0, long cols = 0, long diags = 0, long trans = 0) {
    if (i == n) {
        return 1;
    } else {
        long rt = 0;
        for (int j = 0; j &amp;lt; n; j++) {
            long col = (1 &amp;lt;&amp;lt; j);
            long diag = (1 &amp;lt;&amp;lt; (i - j + n - 1));
            long tran = (1 &amp;lt;&amp;lt; (i + j));
            if (!(col &amp;amp; cols) &amp;amp;&amp;amp; !(diag &amp;amp; diags) &amp;amp;&amp;amp; !(tran &amp;amp; trans)) {
                rt += calc(n, i + 1, col | cols, diag | diags, tran | trans);
            }
        }
        return rt;
    }
}

int main() {
    auto t = chrono::system_clock::now();
    cout &amp;lt;&amp;lt; calc(13) &amp;lt;&amp;lt; endl;
    cout &amp;lt;&amp;lt; (chrono::system_clock::now() - t).count() * 1e-6 &amp;lt;&amp;lt; endl;
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;编译器用的Clang++ 8.1.0，Python解释器则是CPython 3.6.0。由于这里压根不涉及多线程问题，那基本上就跟GIL没有关系了。对于n=13，C++代码跑了0.48秒。为了确保不是编译器悄悄干了活，使用了-O0（实际上开O2能到0.2秒左右）。Python跑了24秒。对于这个例子，最直接的影响其实在于：Python是逐句解释执行的，C++是先编译成本地代码，期间还有编译期的类型检查，不存在动态类型、动态检查，并且可以进行编译器优化。之后应该考虑一下能不能提高一点点效率呢？然后根据一般规律，Python的循环很慢，可以考虑改成列表展开：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def calc(n, i=0, cols=0, diags=0, trans=0):
    if i == n:
        return 1
    else:
        return sum(
            [
                calc(n, i + 1, cols | (1 &amp;lt;&amp;lt; j), diags | (1 &amp;lt;&amp;lt; (i - j + n - 1)), trans | (1 &amp;lt;&amp;lt; (i + j)))
                for j in range(n)
                if (cols &amp;amp; (1 &amp;lt;&amp;lt; j)) == 0 and (diags &amp;amp; (1 &amp;lt;&amp;lt; (i - j + n - 1))) == 0 and (trans &amp;amp; (1 &amp;lt;&amp;lt; (i + j))) == 0
            ]
        )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;理应速度更快，实时也验证了：这样的Python代码需要跑18秒左右。仍然存在数量级的差异，并没有解决根本问题，但是说明了一点，CPython中for loop的实现其实一点都不快。而后考虑一下，如果我们使用其它解释器，特别是包含JIT的解释器，它将在执行过程中尝试将代码编译成本地二进制编码并执行，同时还能赋予一些额外优化，会不会好很多？那么单纯地尝试一下PyPy3(5.8.0-beta, Python 3.5.3)，代码能有多快？实际上，单纯的只是替换一下解释器，换成PyPy来做的话，原本这个24s的Python源码就只需要1s左右了。单单一个JIT可以使得性能提升一个数量级，充分说明官方的CPython解释器的性能不好，PyPy的JIT比较简单纯粹，并不是很激进，但是同样的代码如果能借助更好的JIT，以及更高性能的库，则可以体现出完全不同的性能差。例如，如果使用llvm做JIT，同时加上能使用一些成熟的数学库做优化。我们知道NumPy这样的C扩展能够很大程度提高Python做数值计算的性能，同样的我们也可以用Cython或者直接用C写Python扩展来强化计算能力。但是人都是懒的，重新写代码实在是有些麻烦。对于Python这种生态强大的玩意来说，如果计算代码中只是单纯的使用了numpy的简单结构以及Python自身的标准结构，使用numba可能是最简单快速的办法。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import time


from numba import jit


@jit
def calc(n, i=0, cols=0, diags=0, trans=0):
    if i == n:
        return 1
    else:
        rt = 0
        for j in range(n):
            col = 1 &amp;lt;&amp;lt; j
            diag = 1 &amp;lt;&amp;lt; (i - j + n - 1)
            tran = 1 &amp;lt;&amp;lt; (i + j)

            if (col &amp;amp; cols) == 0 and (diag &amp;amp; diags) == 0 and (tran &amp;amp; trans) == 0:
                rt += calc(n, i+1, cols | col, diags | diag, trans | tran)
        return rt



if __name__ == '__main__':
    t = time.time()
    print(calc(13))
    print(time.time() - t)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里只是很简单地加入了两行代码：从numba导入jit，用jit装饰计算函数。这段代码的运行时间直接就缩短到了0.4s，和C++版本的O0编译后的程序速度几乎一样。这还是考虑到JIT需要预热的情况在内。这段代码，若是计算15的规模，只需要6.5s左右，甚至优于开O2的C++版本。究其原因，JIT不仅仅在运行过程中将代码转为本地机器码，同时还会尝试进行优化。如果用cProfile之类的玩意分析一下运行过程，可以清楚看到这个优化过程。
&lt;/p&gt;
&lt;p&gt;
其实numba也是基于llvm的，这一点没啥差异；差异在于编译的优化是在编译时进行优化，目标代码是保持程序完整功能的；JIT是运行时的即时编译，同样的函数会被JIT编译若干次并在运行时选择最快的，从而优化其性能。例如全在栈空间的问题，C++里每次调用固定了内存大小，但JIT单元可能会在不同的时候使用不同的变量大小，甚至可能直接转成尾递归再优化也说不准……我没去翻JIT结果，也没去深究numba的JIT实现（如果是numba pro，可以确定的是它还直接使用三方库以及SIMD等特性加速），但是提高效果是可以看到的。
&lt;/p&gt;
&lt;p&gt;
编译语言和解释语言，从本质上来说就是完全不同的：编译语言能最终直接对应到机器码。C/C++是典型的编译语言。有JIT的解释语言和真·解释语言，从实现上来说完全不同：JIT可以通过技术手段将解释语言进行重新整理，变成适合编译的结构，然后再转换成机器码，得到接近于编译语言的性能。典型的JIT语言是Java、Javascript同样是解释语言，抽象层次低的语言会比抽象层次高的语言实现起来更容易，运行也更快，典型的如Lua而CPython不巧是那个解释的、没有JIT的、而且抽象层次很高的语言。所以首先CPython就不该跟C++比，最应该比的是Javascript，它跟Javascript比起来最大的负担在于与CPython兼容，比如说支持C API——CPython有一组规定好的数据结构和接口用来让Python和C进行互操作，这个接口保证了Python可以调用C，C也能调用Python，但是这严重妨碍了JIT引擎的设计；再比如CPython的引用计数与标记-扫描混用的GC算法。
&lt;/p&gt;
&lt;p&gt;
JIT又称为准时制生产方式（Just In Time简称JIT），又称作无库存生产方式（stockless production），零库存（zero inventories），一个流（one-piece flow）或者超级市场生产方式（supermarket production）。
&lt;/p&gt;
&lt;p&gt;
JIT是just in time,即时编译技术。使用该技术，能够加速java程序的执行速度。下面，就对该技术做个简单的讲解。
首先，我们大家都知道，通常javac将程序源代码编译，转换成java字节码，JVM通过解释字节码将其翻译成对应的机器指令，逐条读入，逐条解释翻译。很显然，经过解释执行，其执行速度必然会比可执行的二进制字节码程序慢。为了提高执行速度，引入了JIT技术。在运行时JIT会把翻译过的机器码保存起来，已备下次使用，因此从理论上来说，采用该JIT技术可以，可以接近以前纯编译技术。当JIT编译启用时（默认是启用的），JVM读入.class文件解释后，将其发给JIT编译器。JIT编译器将字节码编译成本机机器代码。由于JIT对每条字节码都进行编译，造成了编译过程负担过重。为了避免这种情况，当前的JIT只对经常执行的字节码进行编译，如循环等。需要说明的是，JIT并不总是奏效，不能期望JIT一定能够加速你代码执行的速度，更糟糕的是她有可能降低代码的执行速度。这取决于你的代码结构，当然很多情况下我们还是能够如愿以偿的。
&lt;/p&gt;

&lt;h2 id=&quot;后记&quot;&gt;后记&lt;/h2&gt;

&lt;p&gt;python的效率低还有可能是多线程的问题，下一节总结多线程问题的解决方案。&lt;/p&gt;
</description>
        <pubDate>Sat, 15 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://0.0.0.0:80/2017/07/15/python-1/</link>
        <guid isPermaLink="true">http://0.0.0.0:80/2017/07/15/python-1/</guid>
        
        
      </item>
    
      <item>
        <title>深度学习巨头Yann Lecun 中科院自动化所座谈及清华大学讲座</title>
        <description>&lt;div&gt;
    2017年3月22日星期三，空气重度污染的北京迎来了人工智能领域一位重量级的嘉宾——Facebook人工智能实验室主任，卷积神经网络的发明人Yann Lecun教授。Yann Lecun一行上午在中国科学院自动化研究所举行了40分钟的小型座谈会，下午在清华大学举办了“深度学习与人工智能的未来”主题演讲。笔者有幸全程参与了上述两项活动，现将活动的主要内容及个人感悟与大家分享，欢迎各位分享、转发。未经本人授权，任何组织、个人不得擅自使用本文的文字及图片资料。

    上午 中国科学院自动化研究所智能化大厦17层紫东咖啡厅 主场

    Lecun的到来所里之前也没有做过多的宣传，可能是由于上一次Andrew NG来做报告，整个学术报告厅被挤爆，这一次所里只举行了一个40人左右小而精的座谈会。主要形式以嘉宾和听众互动为主。座谈会的主持人是我们的副所长刘成林研究员，主要嘉宾包括Yann Lecun教授，Facebook 副总裁企业发展副总裁Vaughan Smith博士和田渊栋博士。

    座谈会的开始，刘所长进行了热情而简短的欢迎致辞，接下来就以问答互动的形式开始了座谈。每一个问题我可能无法全部记清楚，现把我自己印象比较深刻的问题简要总结，部分问题在下午清华的讲座中也谈到了。其中一位同学谈到了了深度学习目前还没有相关理论解释的问题。Lecun的观点是，并非所有的研究都是现有理论后有实践，很多问题都是人们先发现了某种现象，后来才找到了合理的理论解释。在下午清华的讲座的QA环节，Lecun又举了几个具体例子，瓦特发明蒸汽机是在动力学理论之前，人们最早发明飞机的时候，也没有完善的空气动力学理论。深度学习就是理论在实践之后。刘所长问了一个关于GAN的问题，Lecun对GAN赞不绝口，并补充说明了GAN不是他自己的idea，是Ian Goodfellow在读博士期间提出来的，下午清华讲座中有关于GAN的详细介绍，这里暂不展开。还有同学问到了哪些领域深度学习并不work，Lecun回答是也谈到了Logistic Regression这些较为经典的模型可以发挥威力的场景。（笔者补充：其实当我们的数据量较小的时候，深度学习的效果可能没有传统的经典模型那么好）。很幸运自己获得了座谈会最后的一个提问机会，我的问题是关于深度学习对抗样本的，深度学习在计算机视觉、语音识别、自然语言处理都取得了突破性的进展，但是研究者也发现深度神经网络也是很容易被愚弄的，当对一张图片加上人为的噪声之后，系统会将其错误分类，类似的现象在强化学习领域里也被观察到，智能体可能会被攻击者误导执行错误的动作，对抗样本和AI的安全密切相关，对此，您有何评论？Lecun说到这是一个很好的问题，他在做手写字符识别的时候也注意到了这种现象，当时为了探索什么图像会让卷积网络完美的预测一个数字4，然后将梯度反向传播的输入图像，所得到的结果和预想的是不一样的。他认为非监督学习是解决对抗样本问题的一个比较有效的思路。在座谈会的最后，刘所长请Yann Lecun教授给在座的同学一句寄语，Lecen教授说我们现在正处于一个AI发展很好的时代，未来AI取得的重要突破，在座的同学就可能扮演重要的角色。教授的谆谆教诲真是给我我等莫大的学习动力。

&lt;/div&gt;
</description>
        <pubDate>Fri, 14 Jul 2017 20:00:00 +0800</pubDate>
        <link>http://0.0.0.0:80/2017/07/14/miui6/</link>
        <guid isPermaLink="true">http://0.0.0.0:80/2017/07/14/miui6/</guid>
        
        <category>知乎</category>
        
        <category>深度学习</category>
        
        
      </item>
    
      <item>
        <title>CNN学习总结(一)</title>
        <description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;#build&quot;&gt;这是一个简单而又痛苦的开始…&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;很久之前就学习了CNN但是一直没有做一个系统性的总结，最近开了博客就总结下。&lt;/p&gt;

&lt;p id=&quot;build&quot;&gt;&lt;/p&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;正文&quot;&gt;正文&lt;/h2&gt;
&lt;p&gt;首先阅读一段CNN代码：https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/convolutional_network.py。在此我截取一部分代码简述一下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from __future__ import print_function

import tensorflow as tf

#导入Import MNIST data
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets(&quot;/tmp/data/&quot;, one_hot=True)

#网络中的超参数
learning_rate = 0.001
training_iters = 200000
batch_size = 128
display_step = 10

#网络参数
n_input = 784 # MNIST data input (img shape: 28*28)
n_classes = 10 # MNIST total classes (0-9 digits)
dropout = 0.75 # Dropout, probability to keep units

#输入占位符
x = tf.placeholder(tf.float32, [None, n_input])
y = tf.placeholder(tf.float32, [None, n_classes])
keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)


#构造卷积层，其中SAME表示越过边缘VAILD代表不越过边缘

def conv2d(x, W, b, strides=1):
    # Conv2D wrapper, with bias and relu activation
    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')
    x = tf.nn.bias_add(x, b)
    return tf.nn.relu(x)


def maxpool2d(x, k=2):
    # MaxPool2D wrapper
    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],
                          padding='SAME')


# Create model
def conv_net(x, weights, biases, dropout):
    # Reshape input picture
    x = tf.reshape(x, shape=[-1, 28, 28, 1])

    # Convolution Layer
    conv1 = conv2d(x, weights['wc1'], biases['bc1'])
    # Max Pooling (down-sampling)
    conv1 = maxpool2d(conv1, k=2)

# Convolution Layer
    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])
# Max Pooling (down-sampling)
    conv2 = maxpool2d(conv2, k=2)

# Fully connected layer
# Reshape conv2 output to fit fully connected layer input
    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])
    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])
    fc1 = tf.nn.relu(fc1)
    # Apply Dropout
    fc1 = tf.nn.dropout(fc1, dropout)
# Output, class prediction
    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])
    return out

# Store layers weight &amp;amp; bias
weights = {
    # 5x5 conv, 1 input, 32 outputs
    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),
    # 5x5 conv, 32 inputs, 64 outputs
    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),
    # fully connected, 7*7*64 inputs, 1024 outputs
    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),
    # 1024 inputs, 10 outputs (class prediction)
    'out': tf.Variable(tf.random_normal([1024, n_classes]))
}

biases = {
    'bc1': tf.Variable(tf.random_normal([32])),
    'bc2': tf.Variable(tf.random_normal([64])),
    'bd1': tf.Variable(tf.random_normal([1024])),
    'out': tf.Variable(tf.random_normal([n_classes]))
}

# Construct model
pred = conv_net(x, weights, biases, keep_prob)

# Define loss and optimizer
cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)

# Evaluate model
correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))
accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))

# Initializing the variables
init = tf.global_variables_initializer()

# Launch the graph
with tf.Session() as sess:
    sess.run(init)
    step = 1
    # Keep training until reach max iterations
    while step * batch_size &amp;lt; training_iters:
        batch_x, batch_y = mnist.train.next_batch(batch_size)
        # Run optimization op (backprop)
        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,
                                       keep_prob: dropout})
        if step % display_step == 0:
            # Calculate batch loss and accuracy
            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,
                                                              y: batch_y,
                                                              keep_prob: 1.})
            print(&quot;Iter &quot; + str(step*batch_size) + &quot;, Minibatch Loss= &quot; + \
                  &quot;{:.6f}&quot;.format(loss) + &quot;, Training Accuracy= &quot; + \
                  &quot;{:.5f}&quot;.format(acc))
        step += 1
    print(&quot;Optimization Finished!&quot;)

# Calculate accuracy for 256 mnist test images
    print(&quot;Testing Accuracy:&quot;, \
        sess.run(accuracy, feed_dict={x: mnist.test.images[:256],
                                      y: mnist.test.labels[:256],
                                      keep_prob: 1.}))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;阅读完代码之后，我们来看一下什么是卷积，卷积神经网络是一种特殊的深层的神经网络模型，它的特殊性体现在两个方面，一方面它的神经元间的连接是非全连接的，另一方面同一层中某些神经元之间的连接的权重是共享的（即相同的）。它的非全连接和权值共享的网络结构使之更类似于生物神经网络，降低了网络模型的复杂度（对于很难学习的深层结构来说，这是非常重要的），减少了权值的数量。&lt;/p&gt;

&lt;p&gt;回想一下BP神经网络。BP网络每一层节点是一个线性的一维排列状态，层与层的网络节点之间是全连接的。这样设想一下，如果BP网络中层与层之间的节点连接不再是全连接，而是局部连接的。这样，就是一种最简单的一维卷积网络。如果我们把上述这个思路扩展到二维，这就是我们在大多数参考资料上看到的卷积神经网络。&lt;/p&gt;

&lt;p&gt;全连接网络。如果我们有1000x1000像素的图像，有1百万个隐层神经元，每个隐层神经元都连接图像的每一个像素点，就有1000x1000x1000000=10^12个连接，也就是10^12个权值参数。&lt;p&gt;

&lt;p&gt;局部连接网络，每一个节点与上层节点同位置附件10x10的窗口相连接，则1百万个隐层神经元就只有100w乘以100，即10^8个参数。其权值连接个数比原来减少了四个数量级。&lt;/p&gt;

#CNN的结构

卷积网络是为识别二维形状而特殊设计的一个多层感知器，这种网络结构对平移、比例缩放、倾斜或者共他形式的变形具有高度不变性。 这些良好的性能是网络在有监督方式下学会的，网络的结构主要有稀疏连接和权值共享两个特点，包括如下形式的约束：
&lt;ul&gt;
&lt;li&gt; 特征提取。每一个神经元从上一层的局部接受域得到突触输人，因而迫使它提取局部特征。一旦一个特征被提取出来，只要它相对于其他特征的位置被近似地保留下来，它的精确位置就变得没有那么重要了。
&lt;/li&gt;
&lt;li&gt;特征映射。网络的每一个计算层都是由多个特征映射组成的，每个特征映射都是平面形式的。平面中单独的神经元在约束下共享相同的突触权值集，这种结构形式具有如下的有益效果：a.平移不变性。b.自由参数数量的缩减(通过权值共享实现)。
&lt;/li&gt;
&lt;li&gt;子抽样。每个卷积层后面跟着一个实现局部平均和子抽样的计算层，由此特征映射的分辨率降低。这种操作具有使特征映射的输出对平移和其他 形式的变形的敏感度下降的作用。
&lt;/li&gt;
&lt;/ul&gt;
卷积神经网络是一个多层的神经网络，每层由多个二维平面组成，而每个平面由多个独立神经元组成。

&lt;img src=&quot;/img/cnn1.png&quot; /&gt;

&lt;p&gt;图：卷积神经网络的概念示范：输入图像通过和三个可训练的滤波器和可加偏置进行卷积，卷积后在C1层产生三个特征映射图，然后特征映射图中每组的四个像素再进行求和，加权值，加偏置，通过一个Sigmoid函数得到三个S2层的特征映射图。这些映射图再进过滤波得到C3层。这个层级结构再和S2一样产生S4。最终，这些像素值被光栅化，并连接成一个向量输入到传统的神经网络，得到输出。&lt;/p&gt;

&lt;p&gt;一般地，C层为特征提取层，每个神经元的输入与前一层的局部感受野相连，并提取该局部的特征，一旦该局部特征被提取后，它与其他特征间的位置关系也随之确定下来；S层是特征映射层，网络的每个计算层由多个特征映射组成，每个特征映射为一个平面，平面上所有神经元的权值相等。特征映射结构采用影响函数核小的sigmoid函数作为卷积网络的激活函数，使得特征映射具有位移不变性。&lt;/p&gt;

&lt;p&gt;此外，由于一个映射面上的神经元共享权值，因而减少了网络自由参数的个数，降低了网络参数选择的复杂度。卷积神经网络中的每一个特征提取层（C-层）都紧跟着一个用来求局部平均与二次提取的计算层（S-层），这种特有的两次特征提取结构使网络在识别时对输入样本有较高的畸变容忍能力。&lt;/p&gt;

#稀疏连接(Sparse Connectivity)

&lt;p&gt;卷积网络通过在相邻两层之间强制使用局部连接模式来利用图像的空间局部特性，在第m层的隐层单元只与第m-1层的输入单元的局部区域有连接，第m-1层的这些局部区域被称为空间连续的接受域。我们可以将这种结构描述如下：设第m-1层为视网膜输入层，第m层的接受域的宽度为3，也就是说该层的每个单元与且仅与输入层的3个相邻的神经元相连，第m层与第m+1层具有类似的链接规则，如下图所示。&lt;/p&gt;

&lt;img src=&quot;/img/cnn2.png&quot; width=&quot;300&quot; /&gt;

&lt;p&gt;可以看到m+1层的神经元相对于第m层的接受域的宽度也为3，但相对于输入层的接受域为5，这种结构将学习到的过滤器（对应于输入信号中被最大激活的单元）限制在局部空间模式（因为每个单元对它接受域外的variation不做反应）。从上图也可以看出，多个这样的层堆叠起来后，会使得过滤器（不再是线性的）逐渐成为全局的（也就是覆盖到了更大的视觉区域）。例如上图中第m+1层的神经元可以对宽度为5的输入进行一个非线性的特征编码。&lt;/p&gt;

#权值共享(Shared Weights)

在卷积网络中，每个稀疏过滤器hi通过共享权值都会覆盖整个可视域，这些共享权值的单元构成一个特征映射，如下图所示。

&lt;img src=&quot;/img/cnn3.png&quot; width=&quot;300&quot; /&gt;

&lt;p&gt;在图中，有3个隐层单元，他们属于同一个特征映射。同种颜色的链接的权值是相同的，我们仍然可以使用梯度下降的方法来学习这些权值，只需要对原始算法做一些小的改动，这里共享权值的梯度是所有共享参数的梯度的总和。我们不禁会问为什么要权重共享呢？一方面，重复单元能够对特征进行识别，而不考虑它在可视域中的位置。另一方面，权值共享使得我们能更有效的进行特征抽取，因为它极大的减少了需要学习的自由变量的个数。通过控制模型的规模，卷积网络对视觉问题可以具有很好的泛化能力。&lt;/p&gt;

#举例讲解：   

上面聊到，好像CNN一个牛逼的地方就在于通过感受野和权值共享减少了神经网络需要训练的参数的个数。那究竟是啥的呢？

下图左：如果我们有1000x1000像素的图像，有1百万个隐层神经元，那么他们全连接的话（每个隐层神经元都连接图像的每一个像素点），就有1000x1000x1000000=10^12个连接，也就是10^12个权值参数。然而图像的空间联系是局部的，就像人是通过一个局部的感受野去感受外界图像一样，每一个神经元都不需要对全局图像做感受，每个神经元只感受局部的图像区域，然后在更高层，将这些感受不同局部的神经元综合起来就可以得到全局的信息了。这样，我们就可以减少连接的数目，也就是减少神经网络需要训练的权值参数的个数了。如下图右：假如局部感受野是10x10，隐层每个感受野只需要和这10x10的局部图像相连接，所以1百万个隐层神经元就只有一亿个连接，即10^8个参数。比原来减少了四个0（数量级），这样训练起来就没那么费力了，但还是感觉很多的啊，那还有啥办法没？

&lt;img src=&quot;/img/cnn4.png&quot; /&gt;

&lt;p&gt;我们知道，隐含层的每一个神经元都连接10x10个图像区域，也就是说每一个神经元存在10x10=100个连接权值参数。那如果我们每个神经元这100个参数是相同的呢？也就是说每个神经元用的是同一个卷积核去卷积图像。这样我们就只有多少个参数？？只有100个参数啊！！！亲！不管你隐层的神经元个数有多少，两层间的连接我只有100个参数啊！亲！这就是权值共享啊！亲！这就是卷积神经网络的主打卖点啊！亲！（有点烦了，呵呵）也许你会问，这样做靠谱吗？为什么可行呢？这个……共同学习。&lt;/p&gt;

&lt;p&gt;假如一种滤波器，也就是一种卷积核就是提出图像的一种特征，例如某个方向的边缘。那么我们需要提取不同的特征，怎么办，加多几种滤波器不就行了吗？对了。所以假设我们加到100种滤波器，每种滤波器的参数不一样，表示它提出输入图像的不同特征，例如不同的边缘。这样每种滤波器去卷积图像就得到对图像的不同特征的放映，我们称之为FeatureMap。所以100种卷积核就有100个Feature Map。这100个FeatureMap就组成了一层神经元。到这个时候明了了吧。我们这一层有多少个参数了？100种卷积核x每种卷积核共享100个参数=100x100=10K，也就是1万个参数。才1万个参数啊！见下图右：不同的颜色表达不同的滤波器。
&lt;/p&gt;
&lt;img src=&quot;/img/cnn5.png&quot; /&gt;

 &lt;p&gt;遗漏一个问题。刚才说隐层的参数个数和隐层的神经元个数无关，只和滤波器的大小和滤波器种类的多少有关。那么隐层的神经元个数怎么确定呢？它和原图像，也就是输入的大小（神经元个数）、滤波器的大小和滤波器在图像中的滑动步长都有关！例如，我的图像是1000x1000像素，而滤波器大小是10x10，假设滤波器没有重叠，也就是步长为10，这样隐层的神经元个数就是(1000x1000 )/ (10x10)=100x100个神经元了，假设步长是8，也就是卷积核会重叠两个像素，那么……我就不算了，思想懂了就好。注意了，这只是一种滤波器，也就是一个FeatureMap的神经元个数哦，如果100个Feature Map就是100倍了。由此可见，图像越大，神经元个数和需要训练的权值参数个数的贫富差距就越大。
 &lt;/p&gt;
 &lt;p&gt;
 需要注意的一点是，上面的讨论都没有考虑每个神经元的偏置部分。所以权值个数需要加1 。这个也是同一种滤波器共享的。
 总之，卷积网络的核心思想是将：局部感受野、权值共享（或者权值复制）以及时间或空间亚采样这三种结构思想结合起来获得了某种程度的位移、尺度、形变不变性。
 &lt;/p&gt;
#The Full Model

&lt;p&gt;卷积神经网络是一个多层的神经网络，每层由多个二维平面组成，而每个平面由多个独立神经元组成。网络中包含一些简单元和复杂元，分别记为S-元和C-元。S-元聚合在一起组成S-面，S-面聚合在一起组成S-层，用Us表示。C-元、C-面和C-层(Us)之间存在类似的关系。网络的任一中间级由S-层与C-层串接而成，而输入级只含一层，它直接接受二维视觉模式，样本特征提取步骤已嵌入到卷积神经网络模型的互联结构中。
&lt;/p&gt;
&lt;p&gt;一般地，Us为特征提取层(子采样层)，每个神经元的输入与前一层的局部感受野相连，并提取该局部的特征，一旦该局部特征被提取后，它与其他特征间的位置关系 也随之确定下来；
&lt;/p&gt;
Uc是特征映射层(卷积层)，网络的每个计算层由多个特征映射组成，每个特征映射为一个平面，平面上所有神经元的权值相等。特征映射结构采用 影响函数核小的sigmoid函数作为卷积网络的激活函数，使得特征映射具有位移不变性。此外，由于一个映射面上的神经元共享权值，因而减少了网络自由参数的个数，降低了网络参数选择的复杂度。卷积神经网络中的每一个特征提取层(S-层)都紧跟着一个 用来求局部平均与二次提取的计算层(C-层)，这种特有的两次特征提取结构使网络在识别时对输入样本有较高的畸变容忍能力。
&lt;/p&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 14 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://0.0.0.0:80/2017/07/14/cnn-1/</link>
        <guid isPermaLink="true">http://0.0.0.0:80/2017/07/14/cnn-1/</guid>
        
        
      </item>
    
      <item>
        <title>Hello 2017</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;“Yeah It’s on. ”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;#build&quot;&gt;跳过废话，直接看技术实现 &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;作为一个程序员， Blog 这种轮子要是挂在大众博客程序上就太没意思了。一是觉得大部分 Blog 服务都太丑，二是觉得不能随便定制不好玩。之前因为太懒没有折腾，结果就一直连个写 Blog 的地儿都没有。&lt;/p&gt;

&lt;p id=&quot;build&quot;&gt;&lt;/p&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;正文&quot;&gt;正文&lt;/h2&gt;

&lt;p&gt;最近几年经过各种理财机构和专家的熏陶，普通人对于“资产配置”一词已经耳熟能详，甚至有点觉得是陈腔滥调了。但其实很多人不知道资产配置的基本原理和具体运用。其实这里包含了三部份：&lt;/p&gt;

&lt;p&gt;(1)市场分析&lt;/p&gt;

&lt;p&gt;(2)配置理论应用&lt;/p&gt;

&lt;p&gt;(3)再平衡方式（再平衡是指当资产组合因为市场波动而偏离了原有状态时，通过及时调整资产比例而实现组合的再平衡，耶鲁投资大师大卫.斯文森将资产配置再平衡形容为“天上掉下的馅饼”）&lt;/p&gt;

&lt;p&gt;而这三者形成了紧密的闭环, 就如同专业媒体常提到的耶鲁投资模式, 其实就是构建了一套完整的机构投资流程和不受市场情绪左右的严谨的投资原则，包括投资目的的设定、资金的进出、资产负债的配比、资产类别的划分及配置、投资品种和投资工具的选择、风险控制、基金经理的选择等。&lt;/p&gt;

&lt;p&gt;需要说明的是，在私人银行和财富管理界，资产配置是有严格要求的，必须以“大类资产配置”为基础，而不能以个股为基础。所谓大类资产，是指股票、债券、地产、黄金等“大类别”的资产，这些资产之间具有分散性，是资产配置的基础。&lt;/p&gt;

&lt;p&gt;无论资产配置的后台是人工还是电脑，这三部分都是必不可少的。但随着大数据技术和机器学习技术的普及，资产配置开始走向智能化，这里就结合我们的经验给大家做一些分享，谈谈机器学习是如何在资产配置中使用的。&lt;/p&gt;

&lt;p&gt;资产配置的理论选择&lt;/p&gt;

&lt;p&gt;模型开发者可根据市场不同情况，利用不同的配置理论与再平衡方式，为投资人提供智能配置与调仓服务, 我们举三种常见的配置组合类型如下：&lt;/p&gt;

&lt;p&gt;懒人组合(1/N):
在这种组合方式里，假设4个投资标的, 则每个配置25%,而懒人组合常搭配的调仓方式有三种, ：&lt;/p&gt;

&lt;p&gt;(a)买入并持有策略(Buy-and-hold Strategy)&lt;/p&gt;

&lt;p&gt;(b)恒定混合策略(Constant-mix Strategy)&lt;/p&gt;

&lt;p&gt;(c)固定比例投资组合保险策略 CPPI(Constant proportion portfolio insurance)&lt;/p&gt;

&lt;p&gt;我们以方法(b) 恒定混合策略为例, 看看当一定期间后该配比与原配置不同时, 触发调整进行再平衡是如何进行的。 首先, 假设我们配置在美国股市、中国股市、债市、黄金各25%,并设定一个季度后做出调整。&lt;/p&gt;

&lt;p&gt;那么在再平衡时, 美股、A股需要调降至25%, 而债市与黄金则需增配至25%, 尔后每季度调整, 即完成再平衡流程, 所以懒人投资法是不需要运用复杂的机器学习的方式。&lt;/p&gt;

&lt;p&gt;风险平价组合(Risk Parity):&lt;/p&gt;

&lt;p&gt;风险平价是对投资组合中不同资产分配相同的风险权重的一种资产配置理念, 在一般情况下股票、商品投资的风险较高, 债券的风险较低, 因此在配置时则会降低高风险资产配置, 使其所贡献的风险相同, 在假设资产相关性相等的条件下, 我们能把某一类资产i 藉由risk-parity计算后, 其配置权重表示如下, 但由于Risk-Parity 并不考虑收益, 只考量波动率(风险)，在实务应用中比较适合能提供良好收益的资产或产品, 因此普遍应用在Fund of funds (FOF)的配置模式, 当大家看完公式后, 是不是觉得你也能成为FOF 投资经理?&lt;/p&gt;

&lt;p&gt;但倘若要成为优秀的投资经理, 就必须对波动率(风险)衡量做番苦工, 传统的方式包括历史波动率模型(Exponential Weighted Moving Average，EWMA)、 隐含波动率模型（Implied Volatility）、以及时间序列一系列模型(GARCH)。&lt;/p&gt;

&lt;p&gt;随着机器学习的崛起,近期也发展出了基于大数据的深度学习模型来预测波动率。比如来自斯坦福大学和Google的学者联合发表了论文“Deep Learning Stock Volatilities with Google Domestic Trends”，利用Google搜索趋势的数据和递归神经元的学习方式来预测股市波动率，其预测效果比传统线性模型或GARCH模型提升31%以上。 因此只要运用得当, 对于采用Risk-Parity的方式, 能提供更好的配置结果。&lt;/p&gt;

&lt;p&gt;马科维茨的均值方差-有效前沿组合或Black-Litterment模型修正:&lt;/p&gt;

&lt;p&gt;有效前沿组合是多数学过金融学的学生都耳熟能详的配置方式, 在有n种资产的投资&lt;/p&gt;

&lt;p&gt;组合中，为各资产的投资权重，对应的收益率为，&lt;/p&gt;

&lt;p&gt;则投资组合的预期收益与险如下：&lt;/p&gt;

&lt;p&gt;模型主要寻找 “收益/风险”(单位风险下的收益)的优化配置组合, 因此优化方程&lt;/p&gt;

&lt;p&gt;表达式如下：&lt;/p&gt;

&lt;p&gt;经由拉格朗日乘值法求解得到的投资权重就是模型的最优投资方案。若把优化投资组合在以标准方差(波动率)为横坐标，预期收益率为纵坐标的二维平面中描绘出来，形成一条曲线。&lt;/p&gt;

&lt;p&gt;这条曲线越往右边投资组合风险越高, 但相对收益也较高, 也符合一般对于高风险对应高收益的认知, 既然有了这个特性, 我们便能将风险选择对应到不同客户属性的配置方案。因此有效前沿组合便成了资产配置的理论基础。&lt;/p&gt;

&lt;p&gt;构造资产配置组合的三大关键点&lt;/p&gt;

&lt;p&gt;现在我们确定用马科维茨的均值方差-有效前沿理论为资产配置组合的基础。&lt;/p&gt;

&lt;p&gt;从这我们可以衍生出三个构造模型的关键点：(1)如何预估风险、 (2)如何预估收益、(3)如何正确的分类用户属性 。&lt;/p&gt;

&lt;p&gt;（1）预估风险&lt;/p&gt;

&lt;p&gt;对于第1点的处理, 可以使用我们上文已经提过到过的，Deep Learning的方式来改善风险预估的困难程度。&lt;/p&gt;

&lt;p&gt;（2）预估收益&lt;/p&gt;

&lt;p&gt;而对于第2点收益预估部份, 运用机器学习好处有：输入资料形态限制较低；可作线性/非线性学习；自我演化、修正等等。机器学习可以对模型因子做出有监督学习, 因子的选择可包含基本面、技术面、筹码面数据, 并做出市场收益的对应估计。下图展示了美国股市运用决策树因子模型分析收益的案例。&lt;/p&gt;

&lt;p&gt;预估收益有多种办法。我们将几种不同的收益预估模型测算出来的资产收益，作为输入参数放入马科维茨的有效前沿模型或者Black-Litterment模型计算，并分析其对投资组合的影响，也就是投资收益的表现。&lt;/p&gt;

&lt;p&gt;下面我们用三种方法来预估收益，一种是支持向量机回归模型（SVM），一种是线性回归模型，这两种模型的分析因子包括利率、市盈率、市净率、股息率、企业盈收、成交值、隐含波动率、MACD、KD等。而第三种则是一般人最常用的，直接用过去几年市场的走势来预测未来市场。&lt;/p&gt;

&lt;p&gt;(3)客户属性分类&lt;/p&gt;

&lt;p&gt;最后我们来看第3点也就是客户分类的机器学习部份，坦率说迄今为止金融机构对用户的数据掌握最多，可以通过记录消费者的消费喜好、收入状况、年龄阶段，推荐客户可能需要的贷款、融资等金融产品。机器学习将用户数据收集后进行规整处理，转化为相同维度的特征向量，通过聚类，回归，关联等各种分类器。&lt;/p&gt;

&lt;p&gt;RFM模型是用户价值研究中的经典模型，基于近度 (Recency)、频度(Frequency)和额度(Monetary)这3个指标对用户进行聚类, 找出具有潜在价值的用户, 从而辅助商业决策，提高营销效率、复购率与转化率, 但多属于单一金融产品营销, 较适合于战术投资配置推荐, 对于风险承受匹配于马科维茨的配置应用则尚未成熟, 因此一般仍以符合监管的主动风险划分方式, 再依据模型优化解帮助客户提供投资资产组合。&lt;/p&gt;

&lt;p&gt;综上所述，我们不难发现机器学习对于资产配置组合的应用实践已经非常丰富, 对于金融机构与资产管理公司来说, 加强金融科技研发人才培育, 可能是未来几年的重要任务。&lt;/p&gt;

&lt;p&gt;参考文献：&lt;/p&gt;

&lt;p&gt;[1] S. Maillard, T. Roncalli and J. Teiletche: The properties of equally-weighted risk contributions portfolios. Journal of Portfolio Management,Vol.36, No.4 pp.60-70,2010.&lt;/p&gt;

&lt;p&gt;[2] R. Xiong, E.P.Nicholas and Y. Shen: Deep learning stock volatilities with google domestic trends. arXiv preprint arXiv:1512.04916,2015.&lt;/p&gt;

&lt;h2 id=&quot;后记&quot;&gt;后记&lt;/h2&gt;

&lt;p&gt;作者：贾宜宸
链接：https://www.zhihu.com/question/58616635/answer/160109081
来源：知乎
著作权归作者所有，转载请联系作者获得授权。&lt;/p&gt;

&lt;p&gt;—— Diane 后记于 2017.7&lt;/p&gt;

</description>
        <pubDate>Thu, 13 Jul 2017 20:00:00 +0800</pubDate>
        <link>http://0.0.0.0:80/2017/07/13/hello-2015/</link>
        <guid isPermaLink="true">http://0.0.0.0:80/2017/07/13/hello-2015/</guid>
        
        <category>生活</category>
        
        
      </item>
    
  </channel>
</rss>
